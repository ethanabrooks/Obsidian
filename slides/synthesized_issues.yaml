system_prompt: >
  You are an AI assistant helping a software development team. Your task is to analyze
  the provided text from a *merged* GitHub Pull Request (including description, comments,
  commits, and diff) and potentially related open issues from the same repository.
  Based *only* on this information, generate the text (title and body) for a *new*,
  plausible GitHub issue that this Pull Request *appears* to resolve. Crucially, the
  generated issue should describe the **problem or symptoms** from the perspective
  of someone encountering the issue *before* the fix was made. Avoid detailing the
  specific solution implemented in the PR. Focus on creating a realistic-sounding
  issue (like a bug report or feature request) that logically connects to the changes
  shown in the PR, but sounds like it was written without knowledge of the final fix.
  Do not invent external context. Output *only* the issue title and body in markdown
  format, starting with the title.

  Example Output Format:

  # Issue Title


  This is the issue body...
results:
  - repository: ansible/ansible
    pr:
      number: 84896
      title: Improve vault filter documentation with clearer examples
      url: https://github.com/ansible/ansible/pull/84896
    status: success
    synthesized_issue: >-
      # Vault filter documentation examples are unclear and incomplete


      The current documentation for the Ansible vault filter lacks clear and comprehensive
      examples, making it difficult for users to understand how to effectively utilize
      this filter. Specifically:


      1. The example for `dump_template_data.j2` is missing, leaving users uncertain
      about how to properly use this template file in conjunction with the vault filter.


      2. The existing examples are inconsistent in their use of variables and variable
      naming conventions, potentially causing confusion among users trying to follow
      along.


      3. The examples lack structure and logical flow, jumping between encryption, saving
      to files, and decryption without a clear progression or explanation of each step.


      4. There is a general lack of detailed guidance on common use cases, such as encrypting
      values for storage in variables, encrypting sensitive data for use in templates,
      and decrypting encrypted data for use in tasks or playbooks.


      To improve the usability and understanding of the vault filter, more comprehensive
      and well-structured examples are needed, along with clear explanations of each
      step and the purpose behind each example. This will help users better grasp the
      full functionality of the vault filter and its applications in securing sensitive
      data within Ansible playbooks and roles.
    llm_prompt:
      "Repository: ansible/ansible\n\n\n--- Context: Existing Open Issues\
      \ ---\nIssue 1 (Number: 84876):\n  Title: [stable-2.17] Fix wait_for examples\
      \ (#84870)\n  Body (Preview):\nconnection: local is wrong as configured remote\
      \ python does not always match controller missing the timeout to wait 300s before\
      \ error\n\n(cherry picked from commit 3690819ee81189d6cbfd62afab1c78554ff0ec76)\n\
      \n\n##### ISSUE TYPE\n\n- Docs Pull Request\n----------\nIssue 2 (Number: 84860):\n\
      \  Title: [stable 2.17] needed intesect, not difference (#84839)\n  Body (Preview):\n\
      fixes #84750\n\nAdded tests to verify output when using smart + others\n\n(cherry\
      \ picked from commit 0d4f00f5c89901e53c2f9c32fa87acac3fed8118)\n\n##### ISSUE\
      \ TYPE\n\n- Bugfix Pull Request\n----------\nIssue 3 (Number: 84926):\n  Title:\
      \ Disconnect `ssh` connection plugin verbosity from Ansible verbosity\n  Body\
      \ (Preview):\nSSH connection plugin verbosity is hardcoded to match Ansible's\
      \ verbosity (e.g., running Ansible with `-vvv` applies `-vvv` to all `ssh` invocations\
      \ as well). This causes a ridiculous amount of unnecessary logging/storage overhead\
      \ (especially for AAP jobs that nearly always run with increased verbosity), pollutes\
      \ `raw` outputs, interpreter discovery diagnostics, and more. It also complicates\
      \ attaining 100% code coverage in some interpreter discovery cases, since `stderr`\
      \ always contains junk.\n\nA...\n----------\nIssue 4 (Number: 84931):\n  Title:\
      \ `--vault-password-file` does not override configuration\n  Body: [Omitted due\
      \ to length (2316 > 2000 chars)]\n----------\nIssue 5 (Number: 84880):\n  Title:\
      \ Make apt clean mark as change only if something was actually cleaned\n  Body:\
      \ [Omitted due to length (2818 > 2000 chars)]\n----------\n(2 issue bodies omitted\
      \ due to length limit of 2000 chars.)\n\n--- Pull Request #84896 Details ---\n\
      PR Title: Improve vault filter documentation with clearer examples\n\nPR Body:\n\
      ##### SUMMARY\nThis PR updates the vault filter documentation by refining the\
      \ examples section to provide clearer and more comprehensive guidance for users.\n\
      \nFixes #83583 \n<!--- Describe the change below, including rationale and design\
      \ decisions -->\n##### What's changed?\n- Added missing template content for dump_template_data.j2,\
      \ ensuring users understand how to use it.\n- Refactored examples to include encryption,\
      \ saving to files, and decryption using unvault.\n- Improved variable consistency\
      \ to prevent confusion.\n- Reorganized the examples for better readability and\
      \ logical flow.\n##### Impact\nUsers raised concerns that the documentation lacked\
      \ explicit content for the dump_template_data.j2 example. Additionally, the examples\
      \ were somewhat inconsistent and unclear. This PR provides a structured, easy-to-follow\
      \ guide for working with the vault filter.\n<!--- Add \"Fixes #1234\" or steps\
      \ to reproduce the problem if there is no corresponding issue -->\n\n##### ISSUE\
      \ TYPE\n\n<!--- Pick one below and delete the rest -->\n\n- Docs Pull Request\n\
      \n\n\n--- Review Comments ---\n\nno, this was added in 2.12\n\nthe existing false\
      \ is correct\n\nor just put the strings directly in the filter, the example makes\
      \ little sense with variable colocation\n\nI would avoid the `# comments` as they\
      \ tend to get stripped in the HTML versions\n\nreverted, apologies!\n\ndone!\n\
      \nyep i removed the most of them just kept a few to elaborate the exmaple, let\
      \ me know what you think!\n\nunvault has it's own examples, its already linked\
      \ in the see also\n\ni would put template in parens in -name, otherwise it makes\
      \ little sense as example once comments are stripped\n\nthis last one seems redundant\n\
      \nremoved the unvault example since it’s already covered elsewhere\n\ni meant\
      \ \n```\n- name: Save vaulted data. (dump_template_data.js: Encrypted secret:\
      \ {{ template_data }})\n```\n\noh got it\n\n\n--- Issue Comments ---\n\nThanks\
      \ for making this change. Do you know if there a standard way of getting the vault\
      \ password into a variable form?\n\nFor example, if I run a playbook:\n```\nansible-playbook\
      \ example.yaml --vault-password-file /path/to/password\n```\n\nHow can I use that\
      \ password in `vault(...)`?\n\n@sf1tzp  you would not need it for `unvault` as\
      \ any vault you access would already be open with any secrets passed into ansible\
      \ itself. As for `vault`, no this is not supported as filter plugins do not currently\
      \ have access to any secrets.\n\n\n--- Commit Messages ---\n\nImprove vault filter\
      \ documentation with clearer examples\n\naddress review comments\n\nupdate\n\n\
      more reviews\n\nminor update\n\nSigned-off-by: Abhijeet Kasurde <Akasurde@redhat.com>\n\
      \n\n--- Diff ---\n\ndiff --git a/changelogs/fragments/vault_docs_fix.yaml b/changelogs/fragments/vault_docs_fix.yaml\n\
      new file mode 100644\nindex 00000000000000..584f505b844367\n--- /dev/null\n+++\
      \ b/changelogs/fragments/vault_docs_fix.yaml\n@@ -0,0 +1,3 @@\n+---\n+minor_changes:\n\
      +  - vault - improved vault filter documentation by adding missing example content\
      \ for dump_template_data.j2, refining examples for clarity, and ensuring variable\
      \ consistency (https://github.com/ansible/ansible/issues/83583).\ndiff --git a/lib/ansible/plugins/filter/vault.yml\
      \ b/lib/ansible/plugins/filter/vault.yml\nindex 8e3437183f4131..d5dbcf0f331598\
      \ 100644\n--- a/lib/ansible/plugins/filter/vault.yml\n+++ b/lib/ansible/plugins/filter/vault.yml\n\
      @@ -32,15 +32,20 @@ DOCUMENTATION:\n       default: False\n \n EXAMPLES: |\n-\
      \  # simply encrypt my key in a vault\n+  # Encrypt a value using the vault filter\n\
      \   vars:\n-    myvaultedkey: \"{{ keyrawdata|vault(passphrase) }} \"\n+    myvaultedkey:\
      \ \"{{ 'my_secret_key' | vault('my_vault_password') }}\"\n \n-  - name: save templated\
      \ vaulted data\n-    template: src=dump_template_data.j2 dest=/some/key/vault.txt\n\
      -    vars:\n-      mysalt: '{{2**256|random(seed=inventory_hostname)}}'\n-   \
      \   template_data: '{{ secretdata|vault(vaultsecret, salt=mysalt) }}'\n+  # Encrypt\
      \ a value and save it to a file using the template module\n+  vars:\n+    template_data:\
      \ \"{{ 'my_sensitive_data' | vault('another_vault_password', salt=(2**256 | random(seed=inventory_hostname)))\
      \ }}\"\n+\n+  # The content of dump_template_data.j2 looks like\n+  #     Encrypted\
      \ secret: {{ template_data }}\n+  - name: Save vaulted data\n+    template:\n\
      +      src: dump_template_data.j2\n+      dest: /some/key/vault.txt\n \n RETURN:\n\
      \   _value:\n\n\n--- Task ---\nBased on the PR details and the context from existing\
      \ issues provided above, please generate the text (title and body) for a new,\
      \ plausible GitHub issue that the pull request #84896 appears to resolve. Output\
      \ only the issue title and body in markdown format.\n"
    diff:
      "diff --git a/changelogs/fragments/vault_docs_fix.yaml b/changelogs/fragments/vault_docs_fix.yaml\n\
      new file mode 100644\nindex 00000000000000..584f505b844367\n--- /dev/null\n+++\
      \ b/changelogs/fragments/vault_docs_fix.yaml\n@@ -0,0 +1,3 @@\n+---\n+minor_changes:\n\
      +  - vault - improved vault filter documentation by adding missing example content\
      \ for dump_template_data.j2, refining examples for clarity, and ensuring variable\
      \ consistency (https://github.com/ansible/ansible/issues/83583).\ndiff --git a/lib/ansible/plugins/filter/vault.yml\
      \ b/lib/ansible/plugins/filter/vault.yml\nindex 8e3437183f4131..d5dbcf0f331598\
      \ 100644\n--- a/lib/ansible/plugins/filter/vault.yml\n+++ b/lib/ansible/plugins/filter/vault.yml\n\
      @@ -32,15 +32,20 @@ DOCUMENTATION:\n       default: False\n \n EXAMPLES: |\n-\
      \  # simply encrypt my key in a vault\n+  # Encrypt a value using the vault filter\n\
      \   vars:\n-    myvaultedkey: \"{{ keyrawdata|vault(passphrase) }} \"\n+    myvaultedkey:\
      \ \"{{ 'my_secret_key' | vault('my_vault_password') }}\"\n \n-  - name: save templated\
      \ vaulted data\n-    template: src=dump_template_data.j2 dest=/some/key/vault.txt\n\
      -    vars:\n-      mysalt: '{{2**256|random(seed=inventory_hostname)}}'\n-   \
      \   template_data: '{{ secretdata|vault(vaultsecret, salt=mysalt) }}'\n+  # Encrypt\
      \ a value and save it to a file using the template module\n+  vars:\n+    template_data:\
      \ \"{{ 'my_sensitive_data' | vault('another_vault_password', salt=(2**256 | random(seed=inventory_hostname)))\
      \ }}\"\n+\n+  # The content of dump_template_data.j2 looks like\n+  #     Encrypted\
      \ secret: {{ template_data }}\n+  - name: Save vaulted data\n+    template:\n\
      +      src: dump_template_data.j2\n+      dest: /some/key/vault.txt\n \n RETURN:\n\
      \   _value:\n"
  - repository: apache/airflow
    pr:
      number: 48782
      title: remove error response for inactivity period in key
      url: https://github.com/apache/airflow/pull/48782
    status: success
    synthesized_issue: >-
      # S3KeysUnchangedSensor failing when no new objects found within inactivity period


      When using the `S3KeysUnchangedSensor` to monitor an S3 bucket for new objects,
      the sensor fails with an error if no new objects are found within the specified
      inactivity period. The expected behavior would be for the sensor to remain in
      a pending state and continue checking until the timeout is reached or new objects
      are detected.


      For example, if the `S3KeysUnchangedSensor` is configured to monitor the `s3://my-bucket/my-prefix/`
      path with an inactivity period of 1 day, and no new objects are added to that
      path for 2 days, the sensor fails with an error message like:


      ```

      FAILURE: Inactivity Period passed, not enough objects found in s3://my-bucket/my-prefix/

      ```


      Instead, the sensor should remain in a pending state and continue checking for
      new objects until the timeout (e.g. 7 days) is reached. This allows DAGs to properly
      handle scenarios where there may be periods of inactivity in the monitored S3
      path, without failing prematurely.
    llm_prompt:
      "Repository: apache/airflow\n\n\n--- Context: Existing Open Issues ---\n\
      Issue 1 (Number: 48849):\n  Title: Remove unnecessary entries in get_provider_info\
      \ and update the schema\n  Body: [Omitted due to length (3338 > 2000 chars)]\n\
      ----------\nIssue 2 (Number: 48844):\n  Title: Scheduler crashing when migrated\
      \ with 2.10.5 DAGRUNS\n  Body: [Omitted due to length (3094 > 2000 chars)]\n----------\n\
      Issue 3 (Number: 48833):\n  Title: Port SecretCache to task sdk\n  Body (Preview):\n\
      ### Body\n\nPort over the secret cache: https://github.com/apache/airflow/blob/main/airflow-core/src/airflow/secrets/cache.py#L27\
      \ to task sdk.\n\n### Committer\n\n- [x] I acknowledge that I am a maintainer/committer\
      \ of the Apache Airflow project.\n----------\nIssue 4 (Number: 48857):\n  Title:\
      \ Task stuck in running state when tried reading asset events using jinja template\n\
      \  Body: [Omitted due to length (2029 > 2000 chars)]\n----------\nIssue 5 (Number:\
      \ 48852):\n  Title: Task in 3.0 gets stuck when fetching larger XCom that can\
      \ be passed without issue in 2.10 + \"Direct database access not allowed error\
      \ upon clearing said task\"\n  Body: [Omitted due to length (4056 > 2000 chars)]\n\
      ----------\n(4 issue bodies omitted due to length limit of 2000 chars.)\n\n---\
      \ Pull Request #48782 Details ---\nPR Title: remove error response for inactivity\
      \ period in key\n\nPR Body:\nWhen running S3KeysUnchangedSensor in deferrable\
      \ mode, `s3_hook_async.is_keys_unchanged_async` returns `{status: 'error'}` when\
      \ there are 'not enough objects'.   \nHowever, this differs from the logic of\
      \ `S3KeysUnchangedSensor.is_keys_unchanged`. The expected behavior is `{status:\
      \ 'pending'}`, so this change makes that correction.\n\n<!--\n Licensed to the\
      \ Apache Software Foundation (ASF) under one\n or more contributor license agreements.\
      \  See the NOTICE file\n distributed with this work for additional information\n\
      \ regarding copyright ownership.  The ASF licenses this file\n to you under the\
      \ Apache License, Version 2.0 (the\n \"License\"); you may not use this file except\
      \ in compliance\n with the License.  You may obtain a copy of the License at\n\
      \n   http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable\
      \ law or agreed to in writing,\n software distributed under the License is distributed\
      \ on an\n \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n KIND, either\
      \ express or implied.  See the License for the\n specific language governing permissions\
      \ and limitations\n under the License.\n -->\n\n<!--\nThank you for contributing!\
      \ Please make sure that your code changes\nare covered with tests. And in case\
      \ of new features or big changes\nremember to adjust the documentation.\n\nFeel\
      \ free to ping committers for the review!\n\nIn case of an existing issue, reference\
      \ it using one of the following:\n\ncloses: #ISSUE\nrelated: #ISSUE\n\nHow to\
      \ write a good git commit message:\nhttp://chris.beams.io/posts/git-commit/\n\
      -->\n\n\n\n<!-- Please keep an empty line above the dashes. -->\n---\n**^ Add\
      \ meaningful description above**\nRead the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)**\
      \ for more information.\nIn case of fundamental code changes, an Airflow Improvement\
      \ Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals))\
      \ is needed.\nIn case of a new dependency, check compliance with the [ASF 3rd\
      \ Party License Policy](https://www.apache.org/legal/resolved.html#category-x).\n\
      In case of backwards incompatible changes please leave a note in a newsfragment\
      \ file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`,\
      \ in [airflow-core/newsfragments](https://github.com/apache/airflow/tree/main/airflow-core/newsfragments).\n\
      \n\n\n--- Commit Messages ---\n\nS3Hook: remove error return on inactivity period\
      \ check\n\n\n--- Diff ---\n\ndiff --git a/providers/amazon/src/airflow/providers/amazon/aws/hooks/s3.py\
      \ b/providers/amazon/src/airflow/providers/amazon/aws/hooks/s3.py\nindex 754207019179b..5455bc102735b\
      \ 100644\n--- a/providers/amazon/src/airflow/providers/amazon/aws/hooks/s3.py\n\
      +++ b/providers/amazon/src/airflow/providers/amazon/aws/hooks/s3.py\n@@ -790,10\
      \ +790,6 @@ async def is_keys_unchanged_async(\n                 \"FAILURE: Inactivity\
      \ Period passed, not enough objects found in %s\",\n                 path,\n \
      \            )\n-            return {\n-                \"status\": \"error\"\
      ,\n-                \"message\": f\"FAILURE: Inactivity Period passed, not enough\
      \ objects found in {path}\",\n-            }\n         return {\n            \
      \ \"status\": \"pending\",\n             \"previous_objects\": previous_objects,\n\
      diff --git a/providers/amazon/tests/unit/amazon/aws/hooks/test_s3.py b/providers/amazon/tests/unit/amazon/aws/hooks/test_s3.py\n\
      index af4b77fffcf86..bb5859516137f 100644\n--- a/providers/amazon/tests/unit/amazon/aws/hooks/test_s3.py\n\
      +++ b/providers/amazon/tests/unit/amazon/aws/hooks/test_s3.py\n@@ -913,9 +913,10\
      \ @@ async def test_s3_key_hook_is_keys_unchanged_async_handle_tzinfo(self, mock_list\n\
      \ \n     @pytest.mark.asyncio\n     @async_mock.patch(\"airflow.providers.amazon.aws.triggers.s3.S3Hook._list_keys_async\"\
      )\n-    async def test_s3_key_hook_is_keys_unchanged_inactivity_error_async(self,\
      \ mock_list_keys):\n+    async def test_s3_key_hook_is_keys_unchanged_inactivity_async(self,\
      \ mock_list_keys):\n         \"\"\"\n-        Test is_key_unchanged gives AirflowException.\n\
      +        Test is_key_unchanged gives False response when the key value is unchanged\
      \ in specified period\n+        and not enough objects found.\n         \"\"\"\
      \n         mock_list_keys.return_value = []\n \n@@ -934,10 +935,7 @@ async def\
      \ test_s3_key_hook_is_keys_unchanged_inactivity_error_async(self, mock_l\n   \
      \          last_activity_time=None,\n         )\n \n-        assert response ==\
      \ {\n-            \"status\": \"error\",\n-            \"message\": \"FAILURE:\
      \ Inactivity Period passed, not enough objects found in test_bucket/test\",\n\
      -        }\n+        assert response.get(\"status\") == \"pending\"\n \n     @pytest.mark.asyncio\n\
      \     @async_mock.patch(\"airflow.providers.amazon.aws.triggers.s3.S3Hook._list_keys_async\"\
      )\n\n\n--- Task ---\nBased on the PR details and the context from existing issues\
      \ provided above, please generate the text (title and body) for a new, plausible\
      \ GitHub issue that the pull request #48782 appears to resolve. Output only the\
      \ issue title and body in markdown format.\n"
    diff:
      "diff --git a/providers/amazon/src/airflow/providers/amazon/aws/hooks/s3.py\
      \ b/providers/amazon/src/airflow/providers/amazon/aws/hooks/s3.py\nindex 754207019179b..5455bc102735b\
      \ 100644\n--- a/providers/amazon/src/airflow/providers/amazon/aws/hooks/s3.py\n\
      +++ b/providers/amazon/src/airflow/providers/amazon/aws/hooks/s3.py\n@@ -790,10\
      \ +790,6 @@ async def is_keys_unchanged_async(\n                 \"FAILURE: Inactivity\
      \ Period passed, not enough objects found in %s\",\n                 path,\n \
      \            )\n-            return {\n-                \"status\": \"error\"\
      ,\n-                \"message\": f\"FAILURE: Inactivity Period passed, not enough\
      \ objects found in {path}\",\n-            }\n         return {\n            \
      \ \"status\": \"pending\",\n             \"previous_objects\": previous_objects,\n\
      diff --git a/providers/amazon/tests/unit/amazon/aws/hooks/test_s3.py b/providers/amazon/tests/unit/amazon/aws/hooks/test_s3.py\n\
      index af4b77fffcf86..bb5859516137f 100644\n--- a/providers/amazon/tests/unit/amazon/aws/hooks/test_s3.py\n\
      +++ b/providers/amazon/tests/unit/amazon/aws/hooks/test_s3.py\n@@ -913,9 +913,10\
      \ @@ async def test_s3_key_hook_is_keys_unchanged_async_handle_tzinfo(self, mock_list\n\
      \ \n     @pytest.mark.asyncio\n     @async_mock.patch(\"airflow.providers.amazon.aws.triggers.s3.S3Hook._list_keys_async\"\
      )\n-    async def test_s3_key_hook_is_keys_unchanged_inactivity_error_async(self,\
      \ mock_list_keys):\n+    async def test_s3_key_hook_is_keys_unchanged_inactivity_async(self,\
      \ mock_list_keys):\n         \"\"\"\n-        Test is_key_unchanged gives AirflowException.\n\
      +        Test is_key_unchanged gives False response when the key value is unchanged\
      \ in specified period\n+        and not enough objects found.\n         \"\"\"\
      \n         mock_list_keys.return_value = []\n \n@@ -934,10 +935,7 @@ async def\
      \ test_s3_key_hook_is_keys_unchanged_inactivity_error_async(self, mock_l\n   \
      \          last_activity_time=None,\n         )\n \n-        assert response ==\
      \ {\n-            \"status\": \"error\",\n-            \"message\": \"FAILURE:\
      \ Inactivity Period passed, not enough objects found in test_bucket/test\",\n\
      -        }\n+        assert response.get(\"status\") == \"pending\"\n \n     @pytest.mark.asyncio\n\
      \     @async_mock.patch(\"airflow.providers.amazon.aws.triggers.s3.S3Hook._list_keys_async\"\
      )\n"
  - repository: aws/aws-cli
    pr:
      number: 9408
      title: Lint botocore and s3transfer with --unsafe-fixes
      url: https://github.com/aws/aws-cli/pull/9408
    status: diff_extraction_failed
  - repository: borgbackup/borg
    pr:
      number: 8722
      title: "tests: ignore 'com.apple.provenance' xattr (macOS specific)"
      url: https://github.com/borgbackup/borg/pull/8722
    status: success
    synthesized_issue: >-
      # Backup fails when backing up files downloaded from the internet on macOS


      The `borg` backup software fails to back up files downloaded from the internet
      on macOS systems. When attempting to back up these files, the following error
      is encountered:


      ```

      ValueError: Unknown extended attribute: com.apple.provenance

      ```


      This error occurs because macOS assigns a special "provenance" extended attribute
      to files downloaded from the internet, in order to track their origin. However,
      the `borg` backup software does not currently handle this extended attribute correctly,
      resulting in the backup failing.


      It would be very helpful if `borg` could properly handle this `com.apple.provenance`
      extended attribute, to allow successful backups of downloaded files on macOS systems.
      Alternatively, if there is a way to configure `borg` to simply ignore this attribute
      during backups, that would also resolve the issue.
    llm_prompt:
      "Repository: borgbackup/borg\n\n\n--- Context: Existing Open Issues\
      \ ---\nIssue 1 (Number: 8723):\n  Title: remove python 3.9 support\n  Body (Preview):\n\
      Python 3.9 will run out of support 2025-10, so guess we will remove testing and\
      \ support for it from borg master branch.\n----------\nIssue 2 (Number: 8671):\n\
      \  Title: Support SOCKS5 proxy\n  Body (Preview):\nHello, thanks for creating\
      \ borg. It's super useful.\n\nIt would be helpful if borg supports SOCKS5 proxying.\
      \ Currently the network I'm in won't allow me to SSH into my backup box, but if\
      \ I was able to use a SOCKS5 proxy it would work. Thanks!\n----------\nIssue 3\
      \ (Number: 8720):\n  Title: Stuttering backup - periodic peaks of CPU, Disks and\
      \ Network usage - why not constantly?\n  Body (Preview):\nDear all,\n\nI've been\
      \ doing backups since one or two years now and was wondering about the long backup\
      \ durations.\n\nTypical backup size of original data is between 5 and 15 TB of\
      \ mostly raw photo and video files located on a NAS with 10GE fiber connection.\
      \ The backup location is a mac computer (2.5GE copper) with a fresh (newly formatted\
      \ exFAT) HDD of 20 TB. This drive is connected to the mac by an USB dock ([https://www.owc.com/solutions/drive-dock](https://www.owc.com/solutions/drive-dock)).\
      \ So...\n----------\nIssue 4 (Number: 8632):\n  Title: Implement chunk comparison\
      \ and selective extraction for borg extract (#5638)\n  Body (Preview):\n## Archive\
      \ File Chunk Comparison and Extraction\n\nThis implementation provides efficient\
      \ file restoration from archives by comparing and extracting chunks. Instead of\
      \ blindly extracting entire files, it:\n\n1. Compares existing file content with\
      \ archived chunks\n2. Only fetches and updates chunks that differ\n3. Handles\
      \ various edge cases:\n   - Partial chunks at end of files\n   - Files longer/shorter\
      \ than archive version\n   - Empty files\n   - Cross-chunk boundary changes\n\
      ----------\nIssue 5 (Number: 8724):\n  Title: The `birthtime` metadata on macOS\
      \ is imprecise\n  Body (Preview):\nPython's `st_birthtime_ns` attribute remains\
      \ unavailable on macOS, despite its introduction in Python 3.12.\n\nThe current\
      \ implementation approximates this value via floating-point arithmetic, which\
      \ introduces precision loss: https://github.com/borgbackup/borg/blob/89daeabd7bd07af2dac201b42fc2b055a1c8440a/src/borg/archive.py#L1075-L1076\n\
      \nThe exact birth time in nanosecond precision can instead be retrieved directly\
      \ via macOS's `stat64` system call.\n----------\n\n--- Pull Request #8722 Details\
      \ ---\nPR Title: tests: ignore 'com.apple.provenance' xattr (macOS specific)\n\
      \nPR Body:\nReference: #8718 \n\ncom.apple.provenance is an extended attribute\
      \ that macOS assigns to files downloaded from the internet, mainly to track their\
      \ origin.\n\n\n\n--- Issue Comments ---\n\n@ThomasWaldmann I have create a new\
      \ PR just like you asked for the attribute fix\n\n## [Codecov](https://app.codecov.io/gh/borgbackup/borg/pull/8722?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=borgbackup)\
      \ Report\nAll modified and coverable lines are covered by tests :white_check_mark:\n\
      > Project coverage is 81.81%. Comparing base [(`72cdf82`)](https://app.codecov.io/gh/borgbackup/borg/commit/72cdf826604385e112b3a84e5465b279c721d8a4?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=borgbackup)\
      \ to head [(`9fa8b58`)](https://app.codecov.io/gh/borgbackup/borg/commit/9fa8b58867a4e156fb7a90535d34ca0944141f4f?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=borgbackup).\n\
      > Report is 4 commits behind head on master.\n\n<details><summary>Additional details\
      \ and impacted files</summary>\n\n\n```diff\n@@            Coverage Diff     \
      \        @@\n##           master    #8722      +/-   ##\n==========================================\n\
      - Coverage   81.85%   81.81%   -0.04%     \n==========================================\n\
      \  Files          74       74              \n  Lines       13338    13348    \
      \  +10     \n  Branches     1969     1971       +2     \n==========================================\n\
      + Hits        10918    10921       +3     \n- Misses       1757     1761     \
      \  +4     \n- Partials      663      666       +3     \n```\n\n</details>\n\n\
      [:umbrella: View full report in Codecov by Sentry](https://app.codecov.io/gh/borgbackup/borg/pull/8722?dropdown=coverage&src=pr&el=continue&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=borgbackup).\
      \   \n:loudspeaker: Have feedback on the report? [Share it here](https://about.codecov.io/codecov-pr-comment-feedback/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=borgbackup).\n\
      \n<details><summary> :rocket: New features to boost your workflow: </summary>\n\
      \n- :snowflake: [Test Analytics](https://docs.codecov.com/docs/test-analytics):\
      \ Detect flaky tests, report on failures, and find test suite problems.\n</details>\n\
      \nThe commit comment is wrong, was that your spellchecker or some AI?\n\nBesides\
      \ the wrong xattr name it mentions, you also never need to mention the names of\
      \ the files you edited or repeat how you changed specific lines in the code -\
      \ if somebody is interested in that, they can use `git diff`.\n\nMost important\
      \ in a commit comment is that it briefly describes what has changed and also why\
      \ it was changed (if that isn't totally obvious). The borg changelog gets made\
      \ from these commit comments, so commit comments directly usable for that are\
      \ best.\n\nI think this is the same commit message you told me to use when I committed\
      \ in the previous PR , if it needs to be changed I will do so\n\nEhrm. The commit\
      \ comment is ok, what I meant was the PR text (which is usually identical, but\
      \ here it wasn't), which you edited now.\n\nThanks for fixing this!\n\n> Ehrm.\
      \ The commit comment is ok, what I meant was the PR text (which is usually identical,\
      \ but here it wasn't), which you edited now.\n\nYess understood! Thank you!\n\n\
      \n--- Commit Messages ---\n\ntests: ignore 'com.apple.provenance' xattr (macOS\
      \ specific)\n\n\n--- Diff ---\n\ndiff --git a/src/borg/testsuite/xattr_test.py\
      \ b/src/borg/testsuite/xattr_test.py\nindex 22f90fef55..89035f7718 100644\n---\
      \ a/src/borg/testsuite/xattr_test.py\n+++ b/src/borg/testsuite/xattr_test.py\n\
      @@ -19,7 +19,7 @@ def tempfile_symlink(tmp_path):\n \n def assert_equal_se(is_x,\
      \ want_x):\n     # check 2 xattr lists for equality, but ignore security.selinux\
      \ attr\n-    is_x = set(is_x) - {b\"security.selinux\"}\n+    is_x = set(is_x)\
      \ - {b\"security.selinux\", b\"com.apple.provenance\"}\n     want_x = set(want_x)\n\
      \     assert is_x == want_x\n \n\n\n--- Task ---\nBased on the PR details and\
      \ the context from existing issues provided above, please generate the text (title\
      \ and body) for a new, plausible GitHub issue that the pull request #8722 appears\
      \ to resolve. Output only the issue title and body in markdown format.\n"
    diff:
      "diff --git a/src/borg/testsuite/xattr_test.py b/src/borg/testsuite/xattr_test.py\n\
      index 22f90fef55..89035f7718 100644\n--- a/src/borg/testsuite/xattr_test.py\n\
      +++ b/src/borg/testsuite/xattr_test.py\n@@ -19,7 +19,7 @@ def tempfile_symlink(tmp_path):\n\
      \ \n def assert_equal_se(is_x, want_x):\n     # check 2 xattr lists for equality,\
      \ but ignore security.selinux attr\n-    is_x = set(is_x) - {b\"security.selinux\"\
      }\n+    is_x = set(is_x) - {b\"security.selinux\", b\"com.apple.provenance\"}\n\
      \     want_x = set(want_x)\n     assert is_x == want_x\n \n"
  - repository: boto/boto3
    pr:
      number: 4494
      title: Bump actions/setup-python from 5.4.0 to 5.5.0
      url: https://github.com/boto/boto3/pull/4494
    status: success
    synthesized_issue: >-
      # Actions/setup-python version incompatibility with boto3


      The `actions/setup-python` action used in the repo's GitHub Actions workflows
      is currently pinned to version 5.4.0. However, this version is no longer compatible
      with the latest boto3 release. When running the tests or linting with the current
      `actions/setup-python@5.4.0`, we encounter errors related to Python version mismatches
      or missing dependencies.


      The tests and linting jobs are failing on the latest commits, blocking further
      development and releases. We need to upgrade the `actions/setup-python` action
      to a newer compatible version to ensure the workflows can run successfully with
      the latest boto3 release.
    llm_prompt: >
      Repository: boto/boto3



      --- Context: Existing Open Issues ---

      Issue 1 (Number: 4449):
        Title: Announcement: Changes to service endpoints for DynamoDB
        Body (Preview):
      In AWS SDK for Python v1.37.0, we will release changes to the DynamoDB client
      that adopt a new AWS account-based endpoints feature. For more information on
      account based endpoints, please refer to the official [SDK documentation](https://docs.aws.amazon.com/sdkref/latest/guide/feature-account-endpoints.html).
      In SDK releases from this version on, clients will connect to a DynamoDB endpoint
      in the form of `(account-id).ddb.(region).amazonaws.com` instead of `dynamodb.(region).amazonaws.com`.


      If...

      ----------

      Issue 2 (Number: 4488):
        Title: using EC2.Client.describe_transit_gateway_vpc_attachments does not list
      all vpc attachments
        Body (Preview):
      ### Describe the bug


      Executing `EC2.Client.describe_transit_gateway_vpc_attachments` does not list
      all transit gateway vpc attachments.

      Expected to display more than 1 attachments. Not sure if it expected or bug.


      ### Regression Issue


      - [ ] Select this option if this issue appears to be a regression.


      ### Expected Behavior


      Expected that it will list all transit gateway vpc attachments


      ### Current Behavior


      only lists 1 attachment. need to 'NextToken' argument to get next attachment.

      example,...

      ----------

      Issue 3 (Number: 4473):
        Title: workaround fork for CRT
        Body (Preview):
      ### Notes:

      - A prove of concept, not ready to merge yet.

      - Needs adding integration tests and polish the code
        - I guess boto3 try to avoid using awscrt directly, I guess we could have s3transfer
      to expose `join_all_native_threads`
        - suggestions are welcome, or feel free to starting new branch if it's easier.
      - It depends on https://github.com/awslabs/aws-crt-python/pull/628, so CI will
      fail until we update the dependency.


      ### Issue:

      - In CRT, we creates background threads, and fork...

      ----------

      Issue 4 (Number: 4497):
        Title: PutObject and DeleteObject is failing with latest version of boto3==1.37
        Body (Preview):
      ### Describe the bug


      Facing following error with Python 3.11 and boto3 latest version 1.37:

      An error occurred (XAmzContentSHA256Mism\

      atch) when calling the PutObject operation: The Content-SHA256 you specified did
      not match what we received.

      For now, downgraded to boto3==1.35.48, and everything is running as expected.


      ### Regression Issue


      - [x] Select this option if this issue appears to be a regression.


      ### Expected Behavior


      PutObject and DeleteObject to run successfully as it was till bo...

      ----------

      Issue 5 (Number: 4465):
        Title: EventBridge client gets InvalidSignatureException when calling PutEvents
      on a Global endpoint in the failover state
        Body: [Omitted due to length (3585 > 2000 chars)]
      ----------

      (1 issue bodies omitted due to length limit of 2000 chars.)


      --- Pull Request #4494 Details ---

      PR Title: Bump actions/setup-python from 5.4.0 to 5.5.0


      PR Body:

      Bumps [actions/setup-python](https://github.com/actions/setup-python) from 5.4.0
      to 5.5.0.

      <details>

      <summary>Release notes</summary>

      <p><em>Sourced from <a href="https://github.com/actions/setup-python/releases">actions/setup-python's
      releases</a>.</em></p>

      <blockquote>

      <h2>v5.5.0</h2>

      <h2>What's Changed</h2>

      <h3>Enhancements:</h3>

      <ul>

      <li>Support free threaded Python versions like '3.13t' by <a href="https://github.com/colesbury"><code>@​colesbury</code></a>
      in <a href="https://redirect.github.com/actions/setup-python/pull/973">actions/setup-python#973</a></li>

      <li>Enhance Workflows: Include ubuntu-arm runners, Add e2e Testing for free threaded
      and Upgrade <code>@​action/cache</code> from 4.0.0 to 4.0.3 by <a href="https://github.com/priya-kinthali"><code>@​priya-kinthali</code></a>
      in <a href="https://redirect.github.com/actions/setup-python/pull/1056">actions/setup-python#1056</a></li>

      <li>Add support for .tool-versions file in setup-python by <a href="https://github.com/mahabaleshwars"><code>@​mahabaleshwars</code></a>
      in <a href="https://redirect.github.com/actions/setup-python/pull/1043">actions/setup-python#1043</a></li>

      </ul>

      <h3>Bug fixes:</h3>

      <ul>

      <li>Fix architecture for pypy on Linux ARM64 by <a href="https://github.com/mayeut"><code>@​mayeut</code></a>
      in <a href="https://redirect.github.com/actions/setup-python/pull/1011">actions/setup-python#1011</a>

      This update maps arm64 to aarch64 for Linux ARM64 PyPy installations.</li>

      </ul>

      <h3>Dependency updates:</h3>

      <ul>

      <li>Upgrade <code>@​vercel/ncc</code> from 0.38.1 to 0.38.3 by <a href="https://github.com/dependabot"><code>@​dependabot</code></a>
      in <a href="https://redirect.github.com/actions/setup-python/pull/1016">actions/setup-python#1016</a></li>

      <li>Upgrade <code>@​actions/glob</code> from 0.4.0 to 0.5.0 by <a href="https://github.com/dependabot"><code>@​dependabot</code></a>
      in <a href="https://redirect.github.com/actions/setup-python/pull/1015">actions/setup-python#1015</a></li>

      </ul>

      <h2>New Contributors</h2>

      <ul>

      <li><a href="https://github.com/colesbury"><code>@​colesbury</code></a> made their
      first contribution in <a href="https://redirect.github.com/actions/setup-python/pull/973">actions/setup-python#973</a></li>

      <li><a href="https://github.com/mahabaleshwars"><code>@​mahabaleshwars</code></a>
      made their first contribution in <a href="https://redirect.github.com/actions/setup-python/pull/1043">actions/setup-python#1043</a></li>

      </ul>

      <p><strong>Full Changelog</strong>: <a href="https://github.com/actions/setup-python/compare/v5...v5.5.0">https://github.com/actions/setup-python/compare/v5...v5.5.0</a></p>

      </blockquote>

      </details>

      <details>

      <summary>Commits</summary>

      <ul>

      <li><a href="https://github.com/actions/setup-python/commit/8d9ed9ac5c53483de85588cdf95a591a75ab9f55"><code>8d9ed9a</code></a>
      Add e2e Testing for free threaded and Bump <code>@​action/cache</code> from 4.0.0
      to 4.0.3 ...</li>

      <li><a href="https://github.com/actions/setup-python/commit/19e4675e06535f6b54e894da5c1f044400bb4996"><code>19e4675</code></a>
      Add support for .tool-versions file in setup-python (<a href="https://redirect.github.com/actions/setup-python/issues/1043">#1043</a>)</li>

      <li><a href="https://github.com/actions/setup-python/commit/6fd11e170a18f6ae448d1080a4a63cc987aed84c"><code>6fd11e1</code></a>
      Bump <code>@​actions/glob</code> from 0.4.0 to 0.5.0 (<a href="https://redirect.github.com/actions/setup-python/issues/1015">#1015</a>)</li>

      <li><a href="https://github.com/actions/setup-python/commit/9e62be81b28222addecf85e47571213eb7680449"><code>9e62be8</code></a>
      Support free threaded Python versions like '3.13t' (<a href="https://redirect.github.com/actions/setup-python/issues/973">#973</a>)</li>

      <li><a href="https://github.com/actions/setup-python/commit/6ca8e8598faa206f7140a65ba31b899bebe16f58"><code>6ca8e85</code></a>
      Bump <code>@​vercel/ncc</code> from 0.38.1 to 0.38.3 (<a href="https://redirect.github.com/actions/setup-python/issues/1016">#1016</a>)</li>

      <li><a href="https://github.com/actions/setup-python/commit/8039c45ed9a312fba91f3399cd0605ba2ebfe93c"><code>8039c45</code></a>
      fix: install PyPy on Linux ARM64 (<a href="https://redirect.github.com/actions/setup-python/issues/1011">#1011</a>)</li>

      <li>See full diff in <a href="https://github.com/actions/setup-python/compare/42375524e23c412d93fb67b49958b491fce71c38...8d9ed9ac5c53483de85588cdf95a591a75ab9f55">compare
      view</a></li>

      </ul>

      </details>

      <br />



      [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=actions/setup-python&package-manager=github_actions&previous-version=5.4.0&new-version=5.5.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)


      Dependabot will resolve any conflicts with this PR as long as you don't alter
      it yourself. You can also trigger a rebase manually by commenting `@dependabot
      rebase`.


      [//]: # (dependabot-automerge-start)

      [//]: # (dependabot-automerge-end)


      ---


      <details>

      <summary>Dependabot commands and options</summary>

      <br />


      You can trigger Dependabot actions by commenting on this PR:

      - `@dependabot rebase` will rebase this PR

      - `@dependabot recreate` will recreate this PR, overwriting any edits that have
      been made to it

      - `@dependabot merge` will merge this PR after your CI passes on it

      - `@dependabot squash and merge` will squash and merge this PR after your CI passes
      on it

      - `@dependabot cancel merge` will cancel a previously requested merge and block
      automerging

      - `@dependabot reopen` will reopen this PR if it is closed

      - `@dependabot close` will close this PR and stop Dependabot recreating it. You
      can achieve the same result by closing it manually

      - `@dependabot show <dependency name> ignore conditions` will show all of the
      ignore conditions of the specified dependency

      - `@dependabot ignore this major version` will close this PR and stop Dependabot
      creating any more for this major version (unless you reopen the PR or upgrade
      to it yourself)

      - `@dependabot ignore this minor version` will close this PR and stop Dependabot
      creating any more for this minor version (unless you reopen the PR or upgrade
      to it yourself)

      - `@dependabot ignore this dependency` will close this PR and stop Dependabot
      creating any more for this dependency (unless you reopen the PR or upgrade to
      it yourself)



      </details>



      --- Commit Messages ---


      Bump actions/setup-python from 5.4.0 to 5.5.0


      Bumps [actions/setup-python](https://github.com/actions/setup-python) from 5.4.0
      to 5.5.0.

      - [Release notes](https://github.com/actions/setup-python/releases)

      - [Commits](https://github.com/actions/setup-python/compare/42375524e23c412d93fb67b49958b491fce71c38...8d9ed9ac5c53483de85588cdf95a591a75ab9f55)


      ---

      updated-dependencies:

      - dependency-name: actions/setup-python
        dependency-type: direct:production
        update-type: version-update:semver-minor
      ...


      Signed-off-by: dependabot[bot] <support@github.com>



      --- Diff ---


      diff --git a/.github/workflows/lint.yml b/.github/workflows/lint.yml

      index 0e20e11ec6..31e7a7c351 100644

      --- a/.github/workflows/lint.yml

      +++ b/.github/workflows/lint.yml

      @@ -15,7 +15,7 @@ jobs:
           steps:
           - uses: actions/checkout@d632683dd7b4114ad314bca15554477dd762a938
           - name: Set up Python 3.9
      -      uses: actions/setup-python@42375524e23c412d93fb67b49958b491fce71c38

      +      uses: actions/setup-python@8d9ed9ac5c53483de85588cdf95a591a75ab9f55
             with:
               python-version: 3.9
           - name: Run pre-commit
      diff --git a/.github/workflows/run-crt-test.yml b/.github/workflows/run-crt-test.yml

      index 1b74415c2e..e1329b9d02 100644

      --- a/.github/workflows/run-crt-test.yml

      +++ b/.github/workflows/run-crt-test.yml

      @@ -20,7 +20,7 @@ jobs:
           steps:
             - uses: actions/checkout@d632683dd7b4114ad314bca15554477dd762a938
             - name: 'Set up Python ${{ matrix.python-version }}'
      -        uses: actions/setup-python@42375524e23c412d93fb67b49958b491fce71c38

      +        uses: actions/setup-python@8d9ed9ac5c53483de85588cdf95a591a75ab9f55
               with:
                 python-version: '${{ matrix.python-version }}'
                 cache: 'pip'
      diff --git a/.github/workflows/run-tests.yml b/.github/workflows/run-tests.yml

      index 9cb830a3e5..65de5ea779 100644

      --- a/.github/workflows/run-tests.yml

      +++ b/.github/workflows/run-tests.yml

      @@ -21,7 +21,7 @@ jobs:
           steps:
           - uses: actions/checkout@d632683dd7b4114ad314bca15554477dd762a938
           - name: Set up Python ${{ matrix.python-version }}
      -      uses: actions/setup-python@42375524e23c412d93fb67b49958b491fce71c38

      +      uses: actions/setup-python@8d9ed9ac5c53483de85588cdf95a591a75ab9f55
             with:
               python-version: ${{ matrix.python-version }}
               cache: 'pip'


      --- Task ---

      Based on the PR details and the context from existing issues provided above, please
      generate the text (title and body) for a new, plausible GitHub issue that the
      pull request #4494 appears to resolve. Output only the issue title and body in
      markdown format.
    diff: >
      diff --git a/.github/workflows/lint.yml b/.github/workflows/lint.yml

      index 0e20e11ec6..31e7a7c351 100644

      --- a/.github/workflows/lint.yml

      +++ b/.github/workflows/lint.yml

      @@ -15,7 +15,7 @@ jobs:
           steps:
           - uses: actions/checkout@d632683dd7b4114ad314bca15554477dd762a938
           - name: Set up Python 3.9
      -      uses: actions/setup-python@42375524e23c412d93fb67b49958b491fce71c38

      +      uses: actions/setup-python@8d9ed9ac5c53483de85588cdf95a591a75ab9f55
             with:
               python-version: 3.9
           - name: Run pre-commit
      diff --git a/.github/workflows/run-crt-test.yml b/.github/workflows/run-crt-test.yml

      index 1b74415c2e..e1329b9d02 100644

      --- a/.github/workflows/run-crt-test.yml

      +++ b/.github/workflows/run-crt-test.yml

      @@ -20,7 +20,7 @@ jobs:
           steps:
             - uses: actions/checkout@d632683dd7b4114ad314bca15554477dd762a938
             - name: 'Set up Python ${{ matrix.python-version }}'
      -        uses: actions/setup-python@42375524e23c412d93fb67b49958b491fce71c38

      +        uses: actions/setup-python@8d9ed9ac5c53483de85588cdf95a591a75ab9f55
               with:
                 python-version: '${{ matrix.python-version }}'
                 cache: 'pip'
      diff --git a/.github/workflows/run-tests.yml b/.github/workflows/run-tests.yml

      index 9cb830a3e5..65de5ea779 100644

      --- a/.github/workflows/run-tests.yml

      +++ b/.github/workflows/run-tests.yml

      @@ -21,7 +21,7 @@ jobs:
           steps:
           - uses: actions/checkout@d632683dd7b4114ad314bca15554477dd762a938
           - name: Set up Python ${{ matrix.python-version }}
      -      uses: actions/setup-python@42375524e23c412d93fb67b49958b491fce71c38

      +      uses: actions/setup-python@8d9ed9ac5c53483de85588cdf95a591a75ab9f55
             with:
               python-version: ${{ matrix.python-version }}
               cache: 'pip'
  - repository: bottlepy/bottle
    pr:
      number: 1473
      title: Update tutorial_app.rst
      url: https://github.com/bottlepy/bottle/pull/1473
    status: diff_extraction_failed
  - repository: celery/celery
    pr:
      number: 9657
      title:
        'Fixed "AttributeError: list object has no attribute strip" with quorum
        queues and failover brokers'
      url: https://github.com/celery/celery/pull/9657
    status: success
    synthesized_issue: >-
      # AttributeError when using quorum queues with failover brokers


      When using quorum queues with multiple failover brokers, Celery raises an `AttributeError`
      with the message "list object has no attribute strip" when attempting to enqueue
      tasks for delayed execution.


      This issue seems to occur when the `broker_url` configuration contains multiple
      URLs separated by semicolons, including empty or whitespace-only URLs. For example:


      ```

      broker_url = "amqp://primary;redis://backup;  ;redis://another-backup"

      ```


      In this configuration, the `broker_url` is split into a list `["amqp://primary",
      "redis://backup", "", "redis://another-backup"]`. When processing this list, Celery
      attempts to call the `strip()` method on each element, causing the error for the
      empty string elements.


      This error prevents tasks from being enqueued for delayed execution when using
      quorum queues with failover brokers configured in this manner. Tasks may be successfully
      enqueued for immediate execution, but any tasks scheduled for delayed execution
      will fail with the `AttributeError`.
    llm_prompt:
      "Repository: celery/celery\n\n\n--- Context: Existing Open Issues ---\n\
      Issue 1 (Number: 9533):\n  Title: Use safe_repr for req.eta in logging extra context\n\
      \  Body (Preview):\n## Description\n\nUsers can define more suitable `logging.Formatter`\
      \ for logging in applications. `\"data\"` in `extra` should be safe for logging\
      \ in different formats like keys `argsrepr` and `kwargsrepr`.\n\nWe use json formatter\
      \ for logging and `json.dumps` fails with `TypeError: Object of type datetime\
      \ is not JSON serializable`.\n\nOf course we can deal with it with\n\n```python\n\
      \ndef custom_json(obj):\n    if isinstance(obj, datetime):\n        return obj.isoformat()\
      \ \n    raise TypeError(f'...\n----------\nIssue 2 (Number: 9620):\n  Title: Revert\
      \ \"Remove dependency on `pycurl`\"\n  Body (Preview):\nReverts celery/celery#9526\n\
      ----------\nIssue 3 (Number: 9586):\n  Title: Redis in celery reconnection every\
      \ submit task\n  Body (Preview):\nIn django `celery.py` is example code\n\n```py\n\
      from __future__ import absolute_import, unicode_literals\n\nfrom celery import\
      \ Celery\nfrom django.conf import settings\nimport redis\n\nimport os\n\nimport\
      \ redis.asyncio\n\n\nos.environ.setdefault(\"DJANGO_SETTINGS_MODULE\", \"internal_proxy.settings\"\
      )\n\napp = Celery(\"internal_proxy\")\n\napp.config_from_object(\"django.conf:settings\"\
      , namespace=\"CELERY\")\n\nbroker_transport_options = {\n    \"connection_pool\"\
      : redis.BlockingConnectionPool.from_url(\n        settings.CELERY...\n----------\n\
      Issue 4 (Number: 9653):\n  Title: crontab() schedule executed one hour too late\
      \ after DST start\n  Body: [Omitted due to length (10120 > 2000 chars)]\n----------\n\
      Issue 5 (Number: 9548):\n  Title: remove Python 3.8 from CI as EOL\n  Body (Preview):\n\
      After celery v5.5.0/v5.5.1 is released in PyPI\n----------\n(1 issue bodies omitted\
      \ due to length limit of 2000 chars.)\n\n--- Pull Request #9657 Details ---\n\
      PR Title: Fixed \"AttributeError: list object has no attribute strip\" with quorum\
      \ queues and failover brokers\n\n\n--- Review Comments ---\n\nI think this test\
      \ case for multiple empty broker URLs would begin failing with the hotfixed code.\
      \  Could we retain it in the parametrized tests?\n\nI've prepared a branch with\
      \ a possible fixup - please let me know whether a PR for this would be welcome.\n\
      \n@jayaddison \n> I think this test case for multiple empty broker URLs would\
      \ begin failing with the hotfixed code. Could we retain it in the parametrized\
      \ tests?\n\nTechnically you’re right. The `\"  ;  ;  “` test case _will_ fail.\n\
      That being said, an empty `broker_url` will default to `amqp` automatically so\
      \ these cases _should never happen_. I did add some checks because we know that\
      \ things that shouldn’t happen do happen, but this is a very rare edge case (`\"\
      \  ;  ;  “`).\n\nThese tests ensure that the private helper method covers the\
      \ basic input cases, but the delayed delivery feature is not responsible for the\
      \ broker URL’s validity.\n\nI’ve removed the use of `strip` to make the broker\
      \ validation just a bit more flexible to balance basic checks with not taking\
      \ full responsibility over `broker_url`.\n\n> I've prepared a branch with a possible\
      \ fixup - please let me know whether a PR for this would be welcome.\n\nDo you\
      \ want to share briefly what is your suggested change to make sure we’re aligned\
      \ before opening a PR?\nI don’t mind improving the coverage as long as we keep\
      \ it simple.\n\nThank you!\n\nThanks @Nusnus!\n\n> > I think this test case for\
      \ multiple empty broker URLs would begin failing with the hotfixed code. Could\
      \ we retain it in the parametrized tests?\n> \n> Technically you’re right. The\
      \ `\" ; ; “` test case _will_ fail. That being said, an empty `broker_url` will\
      \ default to `amqp` automatically so these cases _should never happen_. I did\
      \ add some checks because we know that things that shouldn’t happen do happen,\
      \ but this is a very rare edge case (`\" ; ; “`).\n\nI mostly agree - my line\
      \ of thinking is that if there was a form of misconfiguration we could previously\
      \ detect early, then let's continue to do that.\n \n> These tests ensure that\
      \ the private helper method covers the basic input cases, but the delayed delivery\
      \ feature is not responsible for the broker URL’s validity.\n\n:+1: \n\n> I’ve\
      \ removed the use of `strip` to make the broker validation just a bit more flexible\
      \ to balance basic checks with not taking full responsibility over `broker_url`.\n\
      > \n> > I've prepared a branch with a possible fixup - please let me know whether\
      \ a PR for this would be welcome.\n> \n> Do you want to share briefly what is\
      \ your suggested change to make sure we’re aligned before opening a PR? I don’t\
      \ mind improving the coverage as long as we keep it simple.\n\nThe two modifications\
      \ I'd suggest - both small are:\n\n  * Test coverage: restoring the `\"  ;  ;\
      \  \"` case into the parameterized tests (confirming the problem).\n  * Code fixup:\
      \ restoring the `if url.strip()` conditions into the list comprehension (restoring\
      \ the previous safety mechanism).\n\n@jayaddison \n> The two modifications I'd\
      \ suggest - both small are:\n> \n> * Test coverage: restoring the `\"  ;  ;  \"\
      ` case into the parameterized tests (confirming the problem).\n> * Code fixup:\
      \ restoring the `if url.strip()` conditions into the list comprehension (restoring\
      \ the previous safety mechanism).\n\nI think it’ll be better to have a proper\
      \ global verification method, maybe in Kombu even, and then make sure it is fully\
      \ covered for every edge case including the rare and exotics and use it here instead.\n\
      \nFor now we needed a quick hotfix for the linked bug so I left the `strip`ing\
      \ issue for another time.\n\nOk, thank you.\n\n\n--- Issue Comments ---\n\n##\
      \ [Codecov](https://app.codecov.io/gh/celery/celery/pull/9657?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=celery)\
      \ Report\nAttention: Patch coverage is `84.61538%` with `2 lines` in your changes\
      \ missing coverage. Please review.\n> Project coverage is 78.31%. Comparing base\
      \ [(`d1c35bb`)](https://app.codecov.io/gh/celery/celery/commit/d1c35bbdf014f13f4ab698d75e3ea381a017b090?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=celery)\
      \ to head [(`be74808`)](https://app.codecov.io/gh/celery/celery/commit/be74808166fb1099bbd498a4c6f4593cee8514c8?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=celery).\n\
      \n:white_check_mark: All tests successful. No failed tests found.\n\n| [Files\
      \ with missing lines](https://app.codecov.io/gh/celery/celery/pull/9657?dropdown=coverage&src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=celery)\
      \ | Patch % | Lines |\n|---|---|---|\n| [celery/worker/consumer/delayed\\_delivery.py](https://app.codecov.io/gh/celery/celery/pull/9657?src=pr&el=tree&filepath=celery%2Fworker%2Fconsumer%2Fdelayed_delivery.py&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=celery#diff-Y2VsZXJ5L3dvcmtlci9jb25zdW1lci9kZWxheWVkX2RlbGl2ZXJ5LnB5)\
      \ | 84.61% | [1 Missing and 1 partial :warning: ](https://app.codecov.io/gh/celery/celery/pull/9657?src=pr&el=tree&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=celery)\
      \ |\n\n<details><summary>Additional details and impacted files</summary>\n\n\n\
      ```diff\n@@           Coverage Diff           @@\n##             main    #9657\
      \   +/-   ##\n=======================================\n  Coverage   78.30%   78.31%\
      \           \n=======================================\n  Files         153   \
      \   153           \n  Lines       19116    19125    +9     \n  Branches     2531\
      \     2536    +5     \n=======================================\n+ Hits       \
      \ 14969    14977    +8     \n+ Misses       3859     3858    -1     \n- Partials\
      \      288      290    +2     \n```\n\n| [Flag](https://app.codecov.io/gh/celery/celery/pull/9657/flags?src=pr&el=flags&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=celery)\
      \ | Coverage Δ | |\n|---|---|---|\n| [unittests](https://app.codecov.io/gh/celery/celery/pull/9657/flags?src=pr&el=flag&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=celery)\
      \ | `78.29% <84.61%> (+<0.01%)` | :arrow_up: |\n\nFlags with carried forward coverage\
      \ won't be shown. [Click here](https://docs.codecov.io/docs/carryforward-flags?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=celery#carryforward-flags-in-the-pull-request-comment)\
      \ to find out more.\n\n</details>\n\n[:umbrella: View full report in Codecov by\
      \ Sentry](https://app.codecov.io/gh/celery/celery/pull/9657?dropdown=coverage&src=pr&el=continue&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=celery).\
      \   \n:loudspeaker: Have feedback on the report? [Share it here](https://about.codecov.io/codecov-pr-comment-feedback/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=celery).\n\
      \n\n--- Commit Messages ---\n\nFixed \"AttributeError: list object has no attribute\
      \ strip\" with quorum queues and failover brokers\n\n\n--- Diff ---\n\ndiff --git\
      \ a/.gitignore b/.gitignore\nindex 02c9965790..677430265a 100644\n--- a/.gitignore\n\
      +++ b/.gitignore\n@@ -38,3 +38,4 @@ integration-tests-config.json\n statefilename.*\n\
      \ dump.rdb\n .env\n+junit.xml\ndiff --git a/celery/worker/consumer/delayed_delivery.py\
      \ b/celery/worker/consumer/delayed_delivery.py\nindex d7cacd0806..7a39c60f09 100644\n\
      --- a/celery/worker/consumer/delayed_delivery.py\n+++ b/celery/worker/consumer/delayed_delivery.py\n\
      @@ -3,7 +3,7 @@\n This module provides the DelayedDelivery bootstep which handles\
      \ setup and configuration\n of native delayed delivery functionality when using\
      \ quorum queues.\n \"\"\"\n-from typing import Optional, Set, ValuesView\n+from\
      \ typing import List, Optional, Set, Union, ValuesView\n \n from kombu import\
      \ Connection, Queue\n from kombu.transport.native_delayed_delivery import (bind_queue_to_native_delayed_delivery_exchange,\n\
      @@ -195,22 +195,33 @@ def _validate_configuration(self, app: Celery) -> None:\n\
      \         # Validate queue type\n         self._validate_queue_type(app.conf.broker_native_delayed_delivery_queue_type)\n\
      \ \n-    def _validate_broker_urls(self, urls: str) -> Set[str]:\n+    def _validate_broker_urls(self,\
      \ broker_urls: Union[str, List[str]]) -> Set[str]:\n         \"\"\"Validate and\
      \ split broker URLs.\n \n         Args:\n-            urls: Semicolon-separated\
      \ broker URLs\n+            broker_urls: Broker URLs, either as a semicolon-separated\
      \ string\n+                  or as a list of strings\n \n         Returns:\n \
      \            Set of valid broker URLs\n \n         Raises:\n-            ValueError:\
      \ If no valid broker URLs are found\n+            ValueError: If no valid broker\
      \ URLs are found or if invalid URLs are provided\n         \"\"\"\n-        if\
      \ not urls or not urls.strip():\n+        if not broker_urls:\n             raise\
      \ ValueError(\"broker_url configuration is empty\")\n \n-        valid_urls =\
      \ {url.strip() for url in urls.split(';') if url.strip()}\n+        if isinstance(broker_urls,\
      \ str):\n+            brokers = broker_urls.split(\";\")\n+        elif isinstance(broker_urls,\
      \ list):\n+            if not all(isinstance(url, str) for url in broker_urls):\n\
      +                raise ValueError(\"All broker URLs must be strings\")\n+    \
      \        brokers = broker_urls\n+        else:\n+            raise ValueError(f\"\
      broker_url must be a string or list, got {broker_urls!r}\")\n+\n+        valid_urls\
      \ = {url for url in brokers}\n+\n         if not valid_urls:\n             raise\
      \ ValueError(\"No valid broker URLs found in configuration\")\n \ndiff --git a/t/unit/worker/test_native_delayed_delivery.py\
      \ b/t/unit/worker/test_native_delayed_delivery.py\nindex fecdb514fa..bb1c98b388\
      \ 100644\n--- a/t/unit/worker/test_native_delayed_delivery.py\n+++ b/t/unit/worker/test_native_delayed_delivery.py\n\
      @@ -9,7 +9,7 @@\n \n class test_DelayedDelivery:\n     @patch('celery.worker.consumer.delayed_delivery.detect_quorum_queues',\
      \ return_value=[False, \"\"])\n-    def test_include_if_no_quorum_queues_detected(self,\
      \ detect_quorum_queues):\n+    def test_include_if_no_quorum_queues_detected(self,\
      \ _):\n         consumer_mock = Mock()\n \n         delayed_delivery = DelayedDelivery(consumer_mock)\n\
      @@ -17,7 +17,7 @@ def test_include_if_no_quorum_queues_detected(self, detect_quorum_queues):\n\
      \         assert delayed_delivery.include_if(consumer_mock) is False\n \n    \
      \ @patch('celery.worker.consumer.delayed_delivery.detect_quorum_queues', return_value=[True,\
      \ \"\"])\n-    def test_include_if_quorum_queues_detected(self, detect_quorum_queues):\n\
      +    def test_include_if_quorum_queues_detected(self, _):\n         consumer_mock\
      \ = Mock()\n \n         delayed_delivery = DelayedDelivery(consumer_mock)\n@@\
      \ -74,26 +74,36 @@ def test_start_native_delayed_delivery_fanout_exchange(self,\
      \ caplog):\n \n         assert len(caplog.records) == 0\n \n-    def test_validate_broker_urls_empty(self):\n\
      +    @pytest.mark.parametrize(\n+        \"broker_urls, expected_result\",\n+\
      \        [\n+            (\"amqp://\", {\"amqp://\"}),\n+            (\"amqp://;redis://\"\
      , {\"amqp://\", \"redis://\"}),\n+            (\n+                [\"amqp://\"\
      , \"redis://\", \"sqs://\"],\n+                {\"amqp://\", \"redis://\", \"\
      sqs://\"},\n+            ),\n+        ],\n+    )\n+    def test_validate_broker_urls_valid(self,\
      \ broker_urls, expected_result):\n         delayed_delivery = DelayedDelivery(Mock())\n\
      -\n-        with pytest.raises(ValueError, match=\"broker_url configuration is\
      \ empty\"):\n-            delayed_delivery._validate_broker_urls(\"\")\n-\n- \
      \       with pytest.raises(ValueError, match=\"broker_url configuration is empty\"\
      ):\n-            delayed_delivery._validate_broker_urls(None)\n-\n-    def test_validate_broker_urls_invalid(self):\n\
      +        urls = delayed_delivery._validate_broker_urls(broker_urls)\n+       \
      \ assert urls == expected_result\n+\n+    @pytest.mark.parametrize(\n+       \
      \ \"broker_urls, exception_type, exception_match\",\n+        [\n+           \
      \ (\"\", ValueError, \"broker_url configuration is empty\"),\n+            (None,\
      \ ValueError, \"broker_url configuration is empty\"),\n+            ([], ValueError,\
      \ \"broker_url configuration is empty\"),\n+            (123, ValueError, \"broker_url\
      \ must be a string or list\"),\n+            ([\"amqp://\", 123, None, \"amqp://\"\
      ], ValueError, \"All broker URLs must be strings\"),\n+        ],\n+    )\n+ \
      \   def test_validate_broker_urls_invalid(self, broker_urls, exception_type, exception_match):\n\
      \         delayed_delivery = DelayedDelivery(Mock())\n-\n-        with pytest.raises(ValueError,\
      \ match=\"No valid broker URLs found in configuration\"):\n-            delayed_delivery._validate_broker_urls(\"\
      \  ;  ;  \")\n-\n-    def test_validate_broker_urls_valid(self):\n-        delayed_delivery\
      \ = DelayedDelivery(Mock())\n-\n-        urls = delayed_delivery._validate_broker_urls(\"\
      amqp://localhost;amqp://remote\")\n-        assert urls == {\"amqp://localhost\"\
      , \"amqp://remote\"}\n+        with pytest.raises(exception_type, match=exception_match):\n\
      +            delayed_delivery._validate_broker_urls(broker_urls)\n \n     def\
      \ test_validate_queue_type_empty(self):\n         delayed_delivery = DelayedDelivery(Mock())\n\
      \n\n--- Task ---\nBased on the PR details and the context from existing issues\
      \ provided above, please generate the text (title and body) for a new, plausible\
      \ GitHub issue that the pull request #9657 appears to resolve. Output only the\
      \ issue title and body in markdown format.\n"
    diff:
      "diff --git a/.gitignore b/.gitignore\nindex 02c9965790..677430265a 100644\n\
      --- a/.gitignore\n+++ b/.gitignore\n@@ -38,3 +38,4 @@ integration-tests-config.json\n\
      \ statefilename.*\n dump.rdb\n .env\n+junit.xml\ndiff --git a/celery/worker/consumer/delayed_delivery.py\
      \ b/celery/worker/consumer/delayed_delivery.py\nindex d7cacd0806..7a39c60f09 100644\n\
      --- a/celery/worker/consumer/delayed_delivery.py\n+++ b/celery/worker/consumer/delayed_delivery.py\n\
      @@ -3,7 +3,7 @@\n This module provides the DelayedDelivery bootstep which handles\
      \ setup and configuration\n of native delayed delivery functionality when using\
      \ quorum queues.\n \"\"\"\n-from typing import Optional, Set, ValuesView\n+from\
      \ typing import List, Optional, Set, Union, ValuesView\n \n from kombu import\
      \ Connection, Queue\n from kombu.transport.native_delayed_delivery import (bind_queue_to_native_delayed_delivery_exchange,\n\
      @@ -195,22 +195,33 @@ def _validate_configuration(self, app: Celery) -> None:\n\
      \         # Validate queue type\n         self._validate_queue_type(app.conf.broker_native_delayed_delivery_queue_type)\n\
      \ \n-    def _validate_broker_urls(self, urls: str) -> Set[str]:\n+    def _validate_broker_urls(self,\
      \ broker_urls: Union[str, List[str]]) -> Set[str]:\n         \"\"\"Validate and\
      \ split broker URLs.\n \n         Args:\n-            urls: Semicolon-separated\
      \ broker URLs\n+            broker_urls: Broker URLs, either as a semicolon-separated\
      \ string\n+                  or as a list of strings\n \n         Returns:\n \
      \            Set of valid broker URLs\n \n         Raises:\n-            ValueError:\
      \ If no valid broker URLs are found\n+            ValueError: If no valid broker\
      \ URLs are found or if invalid URLs are provided\n         \"\"\"\n-        if\
      \ not urls or not urls.strip():\n+        if not broker_urls:\n             raise\
      \ ValueError(\"broker_url configuration is empty\")\n \n-        valid_urls =\
      \ {url.strip() for url in urls.split(';') if url.strip()}\n+        if isinstance(broker_urls,\
      \ str):\n+            brokers = broker_urls.split(\";\")\n+        elif isinstance(broker_urls,\
      \ list):\n+            if not all(isinstance(url, str) for url in broker_urls):\n\
      +                raise ValueError(\"All broker URLs must be strings\")\n+    \
      \        brokers = broker_urls\n+        else:\n+            raise ValueError(f\"\
      broker_url must be a string or list, got {broker_urls!r}\")\n+\n+        valid_urls\
      \ = {url for url in brokers}\n+\n         if not valid_urls:\n             raise\
      \ ValueError(\"No valid broker URLs found in configuration\")\n \ndiff --git a/t/unit/worker/test_native_delayed_delivery.py\
      \ b/t/unit/worker/test_native_delayed_delivery.py\nindex fecdb514fa..bb1c98b388\
      \ 100644\n--- a/t/unit/worker/test_native_delayed_delivery.py\n+++ b/t/unit/worker/test_native_delayed_delivery.py\n\
      @@ -9,7 +9,7 @@\n \n class test_DelayedDelivery:\n     @patch('celery.worker.consumer.delayed_delivery.detect_quorum_queues',\
      \ return_value=[False, \"\"])\n-    def test_include_if_no_quorum_queues_detected(self,\
      \ detect_quorum_queues):\n+    def test_include_if_no_quorum_queues_detected(self,\
      \ _):\n         consumer_mock = Mock()\n \n         delayed_delivery = DelayedDelivery(consumer_mock)\n\
      @@ -17,7 +17,7 @@ def test_include_if_no_quorum_queues_detected(self, detect_quorum_queues):\n\
      \         assert delayed_delivery.include_if(consumer_mock) is False\n \n    \
      \ @patch('celery.worker.consumer.delayed_delivery.detect_quorum_queues', return_value=[True,\
      \ \"\"])\n-    def test_include_if_quorum_queues_detected(self, detect_quorum_queues):\n\
      +    def test_include_if_quorum_queues_detected(self, _):\n         consumer_mock\
      \ = Mock()\n \n         delayed_delivery = DelayedDelivery(consumer_mock)\n@@\
      \ -74,26 +74,36 @@ def test_start_native_delayed_delivery_fanout_exchange(self,\
      \ caplog):\n \n         assert len(caplog.records) == 0\n \n-    def test_validate_broker_urls_empty(self):\n\
      +    @pytest.mark.parametrize(\n+        \"broker_urls, expected_result\",\n+\
      \        [\n+            (\"amqp://\", {\"amqp://\"}),\n+            (\"amqp://;redis://\"\
      , {\"amqp://\", \"redis://\"}),\n+            (\n+                [\"amqp://\"\
      , \"redis://\", \"sqs://\"],\n+                {\"amqp://\", \"redis://\", \"\
      sqs://\"},\n+            ),\n+        ],\n+    )\n+    def test_validate_broker_urls_valid(self,\
      \ broker_urls, expected_result):\n         delayed_delivery = DelayedDelivery(Mock())\n\
      -\n-        with pytest.raises(ValueError, match=\"broker_url configuration is\
      \ empty\"):\n-            delayed_delivery._validate_broker_urls(\"\")\n-\n- \
      \       with pytest.raises(ValueError, match=\"broker_url configuration is empty\"\
      ):\n-            delayed_delivery._validate_broker_urls(None)\n-\n-    def test_validate_broker_urls_invalid(self):\n\
      +        urls = delayed_delivery._validate_broker_urls(broker_urls)\n+       \
      \ assert urls == expected_result\n+\n+    @pytest.mark.parametrize(\n+       \
      \ \"broker_urls, exception_type, exception_match\",\n+        [\n+           \
      \ (\"\", ValueError, \"broker_url configuration is empty\"),\n+            (None,\
      \ ValueError, \"broker_url configuration is empty\"),\n+            ([], ValueError,\
      \ \"broker_url configuration is empty\"),\n+            (123, ValueError, \"broker_url\
      \ must be a string or list\"),\n+            ([\"amqp://\", 123, None, \"amqp://\"\
      ], ValueError, \"All broker URLs must be strings\"),\n+        ],\n+    )\n+ \
      \   def test_validate_broker_urls_invalid(self, broker_urls, exception_type, exception_match):\n\
      \         delayed_delivery = DelayedDelivery(Mock())\n-\n-        with pytest.raises(ValueError,\
      \ match=\"No valid broker URLs found in configuration\"):\n-            delayed_delivery._validate_broker_urls(\"\
      \  ;  ;  \")\n-\n-    def test_validate_broker_urls_valid(self):\n-        delayed_delivery\
      \ = DelayedDelivery(Mock())\n-\n-        urls = delayed_delivery._validate_broker_urls(\"\
      amqp://localhost;amqp://remote\")\n-        assert urls == {\"amqp://localhost\"\
      , \"amqp://remote\"}\n+        with pytest.raises(exception_type, match=exception_match):\n\
      +            delayed_delivery._validate_broker_urls(broker_urls)\n \n     def\
      \ test_validate_queue_type_empty(self):\n         delayed_delivery = DelayedDelivery(Mock())\n"
  - repository: certbot/certbot
    pr:
      number: 10255
      title: cloudtest some warnings
      url: https://github.com/certbot/certbot/pull/10255
    status: success
    synthesized_issue: >-
      # TLS-ALPN-01 Challenge Causes Deprecation Warnings


      Certbot is currently experiencing deprecation warnings when using the TLS-ALPN-01
      challenge. This challenge requires the use of PyOpenSSL, which is triggering the
      following warnings:


      1. Passing pyOpenSSL X509 objects is deprecated

      2. Passing pyOpenSSL PKey objects is deprecated


      These warnings are likely caused by PyOpenSSL's deprecated usage of its own X509
      and PKey objects, which are being replaced by the cryptography library's implementations.


      When running Certbot, especially with the `--dry-run` or `--test-cert` flags,
      these warnings are printed to the console, making the output harder to read and
      potentially causing confusion for users.


      A clean solution to this issue would be to either:


      1. Update the TLS-ALPN-01 challenge code to use cryptography's X509 and PKey objects
      instead of PyOpenSSL's deprecated implementations.

      2. Temporarily suppress these specific warnings until the TLS-ALPN-01 challenge
      can be updated or potentially removed in the future.


      Either approach would help to reduce noise in the console output and provide a
      better user experience when running Certbot.
    llm_prompt:
      "Repository: certbot/certbot\n\n\n--- Context: Existing Open Issues\
      \ ---\nIssue 1 (Number: 10195):\n  Title: Handle deprecation of `typing` module\
      \ in PEP-0585\n  Body (Preview):\nhttps://peps.python.org/pep-0585/\n\n>  starting\
      \ with Python 3.9, the following collections become generic using __class_getitem__()\
      \ to parameterize contained types:\n> tuple # typing.Tuple\n> list # typing.List\n\
      > dict # typing.Dict\n> set # typing.Set\n> [... and a bunch more ...]\n> Importing\
      \ those from typing is deprecated. Due to [PEP 563](https://peps.python.org/pep-0563/)\
      \ and the intention to minimize the runtime impact of typing, this deprecation\
      \ will not generate DeprecationWarnings. Instead, t...\n----------\nIssue 2 (Number:\
      \ 10256):\n  Title: [Feature Request]: Performance improvements\n  Body (Preview):\n\
      ### What problem does this feature solve or what does it enhance?\n\nWe've seen\
      \ a number of issues related to Certbot not performing well, especially when renewing\
      \ a large number of certificates. This issue is meant to collect those under one\
      \ umbrella for easier tracking:\n\n* https://github.com/certbot/certbot/issues/10083\n\
      * https://github.com/certbot/certbot/issues/10107\n* https://github.com/certbot/certbot/issues/10219\n\
      * https://github.com/certbot/certbot/issues/10246\n----------\nIssue 3 (Number:\
      \ 10219):\n  Title: Certbot hangs on auto and manual renewal, but never errors\
      \ out\n  Body: [Omitted due to length (5170 > 2000 chars)]\n----------\nIssue\
      \ 4 (Number: 10189):\n  Title: Certbot does not include Let's Encrypt Root CA\
      \ in fullchain.pem\n  Body (Preview):\nWhen generating a wildcard certificate\
      \ using Certbot with the following command:\n\nsh\nCopy\nEdit\ncertbot certonly\
      \ --manual \\\n  --preferred-challenges=dns \\\n  --email $EMAIL \\\n  --server\
      \ https://acme-v02.api.letsencrypt.org/directory \\\n  --agree-tos \\\n  --config-dir\
      \ \"$SCRATCH_DIR/config\" \\\n  --work-dir \"$SCRATCH_DIR/work\" \\\n  --logs-dir\
      \ \"$SCRATCH_DIR/logs\" \\\n  -d \"*.$DOMAIN\"\nCertbot creates a fullchain.pem\
      \ file that does not include Let's Encrypt's root CA. This caused issues when\
      \ trying to route...\n----------\nIssue 5 (Number: 10148):\n  Title: standalone\
      \ + post_hook causing renewal issues when using multiple authenticators\n  Body\
      \ (Preview):\n## My operating system is (include version):\nDebian 12\n\n## I\
      \ installed Certbot with (snap, OS package manager, pip, certbot-auto, etc):\n\
      Problem is on all above.\n\n## I ran this comand and it produced this output:\n\
      \nWhen running `certbot renew` command and having mixed standalone + webroot certificates,\
      \ if any of standalone renewal fails, subsequent webroot renewal will fail as\
      \ well. That's when standalone method utilizes pre/post (i.e. nginx stop). That's\
      \ because certbot is combining all post-hook...\n----------\n(1 issue bodies omitted\
      \ due to length limit of 2000 chars.)\n\n--- Pull Request #10255 Details ---\n\
      PR Title: cloudtest some warnings\n\n\n--- Issue Comments ---\n\n@wgreenberg This\
      \ clears out most of the warnings.\n\nI've taken a second look at the code, and\
      \ it looks like the last holdouts of PyOpenSSL objects being passed could be removed.\
      \  PyOpenSSL is still needed for TLS-ALPN-01, but it looks like the input/output\
      \ of these functions could be changed to Cryptography objects.  They might need\
      \ deprecation warnings first though.\n\nI quickly went through the code that still\
      \ leverages crypto objects.\n\nIt seems like the could be changed to accept/return\
      \ Cryptography objects and then translate as needed.  Some already do this with\
      \ certain args, but not others.\n\nThe deprecation candidates would be here: https://github.com/jvanasco/certbot/pull/4/files\n\
      \nThese functions either:\n\n* accept/return a crypto object \n* accept/return\
      \ a type alias with a crypto object\n\nIf you're looking to do a new release this\
      \ week, I would try to deprecate the args now.\n\nthanks for looking into this\
      \ @jvanasco! we're going to discuss the future of TLS-ALPN-01 today.\n\nfor this\
      \ PR, the comment above the filter section is meant to have each numbered line\
      \ describe the corresponding filter in order. would you mind deleting & renumbering\
      \ the comments to match the new order?\n\nDone.  I actually missed pushing a commit\
      \ that renumbered differently, so I'm glad you requested this and I could catch\
      \ and correct this mistake.\n\nI think the TLS-ALPN would work fine with Crytography\
      \ inputs/outputs.  The only issue would be doing a release to first emit deprecation\
      \ warnings of those functions if required.\n\nlgtm! ultimately i think we're going\
      \ to be deprecating TLS-ALPN-01 support from ACME, which we'll handle in a separate\
      \ issue\n\n\n--- Commit Messages ---\n\ncloudtest some warnings\n\ntry #2\n\n\
      try 3\n\nfinal warnings tracker\n\nrequested change\n\nmissed save\n\n\n--- Diff\
      \ ---\n\ndiff --git a/pytest.ini b/pytest.ini\nindex 46f2766ac8..6a08ab57d2 100644\n\
      --- a/pytest.ini\n+++ b/pytest.ini\n@@ -19,24 +19,13 @@\n #    updated.\n # 3)\
      \ Ignore DeprecationWarning for datetime.utcfromtimestamp() triggered\n #    from\
      \ dateutil. See https://github.com/dateutil/dateutil/issues/1314.\n-# 4) Ignoring\
      \ this allows us to continue to update pyOpenSSL (one of our crypto\n-#    dependencies)\
      \ until https://github.com/certbot/certbot/issues/9828 is resolved.\n-# 5) CSR\
      \ support is deprecated in pyOpenSSL since 24.2, we silence\n-#    the warning\
      \ until https://github.com/certbot/certbot/issues/9992 is resolved.\n-# 6) pyOpenSSL\
      \ 24.3 deprecated methods using pyOpenSSL X509Extension objects.\n-#    Fixing\
      \ this should also be resolved by the work on\n-#    https://github.com/certbot/certbot/issues/9828\
      \ and the open PR\n-#    https://github.com/certbot/certbot/pull/9909 currently\
      \ resolves this issue.\n-# 7 & 8) Resolving these warnings is being tracked by\n\
      +# 4 & 5) The pyOpenSSL X509/PKey warnings are due to TLS-ALPN-01 support.\n+#\
      \    Resolving these warnings is being tracked by\n #        https://github.com/certbot/certbot/issues/10079.\n\
      \ filterwarnings =\n     error\n     ignore:.*rsyncdir:DeprecationWarning\n  \
      \   ignore:'urllib3.contrib.pyopenssl:DeprecationWarning:requests_toolbelt\n \
      \    ignore:.*datetime.utcfromtimestamp\\(\\) is deprecated:DeprecationWarning:dateutil\n\
      -    ignore:X509Extension support in pyOpenSSL is deprecated:DeprecationWarning\n\
      -    ignore:CSR support in pyOpenSSL is deprecated:DeprecationWarning\n-    ignore:.*You\
      \ should use pyca/cryptography's X.509 APIs:DeprecationWarning\n-    ignore:Passing\
      \ pyOpenSSL PKey objects is deprecated:DeprecationWarning\n     ignore:Passing\
      \ pyOpenSSL X509 objects is deprecated:DeprecationWarning\n-    ignore:The next\
      \ major version of josepy will remove:DeprecationWarning\n+    ignore:Passing\
      \ pyOpenSSL PKey objects is deprecated:DeprecationWarning\n\n\n--- Task ---\n\
      Based on the PR details and the context from existing issues provided above, please\
      \ generate the text (title and body) for a new, plausible GitHub issue that the\
      \ pull request #10255 appears to resolve. Output only the issue title and body\
      \ in markdown format.\n"
    diff: >
      diff --git a/pytest.ini b/pytest.ini

      index 46f2766ac8..6a08ab57d2 100644

      --- a/pytest.ini

      +++ b/pytest.ini

      @@ -19,24 +19,13 @@
       #    updated.
       # 3) Ignore DeprecationWarning for datetime.utcfromtimestamp() triggered
       #    from dateutil. See https://github.com/dateutil/dateutil/issues/1314.
      -# 4) Ignoring this allows us to continue to update pyOpenSSL (one of our crypto

      -#    dependencies) until https://github.com/certbot/certbot/issues/9828 is resolved.

      -# 5) CSR support is deprecated in pyOpenSSL since 24.2, we silence

      -#    the warning until https://github.com/certbot/certbot/issues/9992 is resolved.

      -# 6) pyOpenSSL 24.3 deprecated methods using pyOpenSSL X509Extension objects.

      -#    Fixing this should also be resolved by the work on

      -#    https://github.com/certbot/certbot/issues/9828 and the open PR

      -#    https://github.com/certbot/certbot/pull/9909 currently resolves this issue.

      -# 7 & 8) Resolving these warnings is being tracked by

      +# 4 & 5) The pyOpenSSL X509/PKey warnings are due to TLS-ALPN-01 support.

      +#    Resolving these warnings is being tracked by
       #        https://github.com/certbot/certbot/issues/10079.
       filterwarnings =
           error
           ignore:.*rsyncdir:DeprecationWarning
           ignore:'urllib3.contrib.pyopenssl:DeprecationWarning:requests_toolbelt
           ignore:.*datetime.utcfromtimestamp\(\) is deprecated:DeprecationWarning:dateutil
      -    ignore:X509Extension support in pyOpenSSL is deprecated:DeprecationWarning

      -    ignore:CSR support in pyOpenSSL is deprecated:DeprecationWarning

      -    ignore:.*You should use pyca/cryptography's X.509 APIs:DeprecationWarning

      -    ignore:Passing pyOpenSSL PKey objects is deprecated:DeprecationWarning
           ignore:Passing pyOpenSSL X509 objects is deprecated:DeprecationWarning
      -    ignore:The next major version of josepy will remove:DeprecationWarning

      +    ignore:Passing pyOpenSSL PKey objects is deprecated:DeprecationWarning
  - repository: cherrypy/cherrypy
    pr:
      number: 2045
      title: random cheroot related test suite failures with Python 3.13
      url: https://github.com/cherrypy/cherrypy/pull/2045
    status: success
    synthesized_issue: >-
      # Random test failures with Python 3.13


      In the test suite for CherryPy, some tests related to the Cheroot WSGI server
      are failing randomly when running with Python 3.13. The failures seem to be related
      to unclosed sockets or race conditions during the cleanup of socket connections.


      When executing the test suite with Python 3.13, the following errors or warnings
      are encountered:


      ```

      ResourceWarning: unclosed <socket.socket fd=X>

      pytest.PytestUnraisableExceptionWarning: Exception ignored in: <function IOBase.__del__

      ```


      These warnings and failures do not occur consistently, but appear to happen randomly
      across different test runs or on different systems. The root cause is likely a
      race condition or timing issue when closing connections or sockets during the
      teardown phase of certain tests.


      The failures prevent the test suite from completing successfully and need to be
      addressed to ensure compatibility and stability with the upcoming Python 3.13
      release.
    llm_prompt:
      "Repository: cherrypy/cherrypy\n\n\n--- Context: Existing Open Issues\
      \ ---\nIssue 1 (Number: 2018):\n  Title: Connections are not closed when chunked\
      \ message bodies fail to parse.\n  Body: [Omitted due to length (2922 > 2000 chars)]\n\
      ----------\nIssue 2 (Number: 2003):\n  Title: Fix Sensitive Data Exposure: Set\
      \ `umask` to default value after use\n  Body: [Omitted due to length (4300 > 2000\
      \ chars)]\n----------\nIssue 3 (Number: 1994):\n  Title: InternalRedirect access\
      \ logging -> log original request instead of redirected\n  Body (Preview):\nHello,\n\
      \nthis is a bug/feature request (not sure what exactly matches).\n\nI'm using\
      \ a default implementation for an online shop using regex for \"beautiful urls\"\
      .\n\nFor reroute the request I use the InternalRedirect Exception, which works\
      \ fine.\nBut at the access log there appears the redirected entry instead of the\
      \ original one.\nHow can I log the original entry instead?\n\n\n```\nimport cherrypy\n\
      \nclass Root:\n    @cherrypy.expose\n    def default(self, *args, **kwargs):\n\
      \        print('def...\n----------\nIssue 4 (Number: 1987):\n  Title: problems\
      \ with outgoing secure connections\n  Body (Preview):\n**I'm submitting a ...**\n\
      - [ ] bug report\n\n**What is the current behavior?**\n\nin my cherrypy project,\
      \ a module (rosreestr2coord) is used, which should access the site api over a\
      \ secure connection and receive the necessary content. When this module is run\
      \ through the interpreter, or just through a file, then everything is in order.\
      \ But when this module is used in a running cherrypy server, a connection refused\
      \ occurs.\n\n**If the current behavior is a bug, please provide the steps to reprodu...\n\
      ----------\nIssue 5 (Number: 2024):\n  Title: cherrypy.tools.static loses with\
      \ a TypeError in httputil.get_ranges() when asked to serve a range from a fileobj\
      \ representing a zipfile entry\n  Body: [Omitted due to length (5971 > 2000 chars)]\n\
      ----------\n(3 issue bodies omitted due to length limit of 2000 chars.)\n\n---\
      \ Pull Request #2045 Details ---\nPR Title: random cheroot related test suite\
      \ failures with Python 3.13\n\nPR Body:\n**What kind of change does this PR introduce?**\n\
      \  - [X] bug fix\n  - [ ] feature\n  - [ ] docs update\n  - [X] tests/coverage\
      \ improvement\n  - [ ] refactoring\n  - [ ] other\n\n**What is the related issue\
      \ number (starting with `#`)**\n\nResolves #2044\n\n\n\n--- Commit Messages ---\n\
      \nrandom cheroot related test suite failures with Python 3.13\n\n\n--- Diff ---\n\
      \ndiff --git a/pytest.ini b/pytest.ini\nindex bcecc9bd5..ed7c2160e 100644\n---\
      \ a/pytest.ini\n+++ b/pytest.ini\n@@ -63,6 +63,10 @@ filterwarnings =\n   # TODO:\
      \ connection properly.\n   ignore:unclosed <socket.socket fd=:ResourceWarning\n\
      \ \n+  # Python 3.13 no longer ignores IOBase errors raised by the close(),\n\
      +  # which exposed a possible race condition in cheroot test class.\n+  ignore:Exception\
      \ ignored in. <function IOBase.__del__:pytest.PytestUnraisableExceptionWarning\n\
      +\n junit_duration_report = call\n junit_family = xunit2\n junit_suite_name =\
      \ cherrypy_test_suite\n\n\n--- Task ---\nBased on the PR details and the context\
      \ from existing issues provided above, please generate the text (title and body)\
      \ for a new, plausible GitHub issue that the pull request #2045 appears to resolve.\
      \ Output only the issue title and body in markdown format.\n"
    diff:
      "diff --git a/pytest.ini b/pytest.ini\nindex bcecc9bd5..ed7c2160e 100644\n\
      --- a/pytest.ini\n+++ b/pytest.ini\n@@ -63,6 +63,10 @@ filterwarnings =\n   #\
      \ TODO: connection properly.\n   ignore:unclosed <socket.socket fd=:ResourceWarning\n\
      \ \n+  # Python 3.13 no longer ignores IOBase errors raised by the close(),\n\
      +  # which exposed a possible race condition in cheroot test class.\n+  ignore:Exception\
      \ ignored in. <function IOBase.__del__:pytest.PytestUnraisableExceptionWarning\n\
      +\n junit_duration_report = call\n junit_family = xunit2\n junit_suite_name =\
      \ cherrypy_test_suite\n"
  - repository: conan-io/conan
    pr:
      number: 18030
      title: add test_divergent_cppstd_build_host test
      url: https://github.com/conan-io/conan/pull/18030
    status: success
    synthesized_issue: >-
      # Compiler setting for host context and build context not applied correctly


      When building a Conan package with divergent compiler settings between the host
      context and build context, the package ID computation is not considering the different
      settings. This leads to incorrect package IDs being used, potentially causing
      build issues or runtime errors.


      For example, when building a package with `compiler.cppstd=14` for the host context
      and `compiler.cppstd=17` for the build context, the package IDs generated for
      the host and build contexts are the same, despite the different compiler settings.


      This issue is exacerbated when the package has dependencies with the same divergent
      compiler settings, as the incorrect package IDs propagate through the dependency
      graph.


      The expected behavior is for Conan to generate separate package IDs for the host
      and build contexts when their compiler settings differ, ensuring that the correct
      packages are used for each context.
    llm_prompt:
      "Repository: conan-io/conan\n\n\n--- Context: Existing Open Issues ---\n\
      Issue 1 (Number: 18061):\n  Title: [question] SHORT DESCRIPTION: conan2 migration\
      \ of self.env_info which is used in package_info\n  Body (Preview):\n### What\
      \ is your question?\n\nHi @memsharded, \n\nIn one of my conan1 recipe \"golang\"\
      , in package_info(self), I have this line:\n`self.env_info.GO = path.join(self.package_folder,\
      \ \"bin\", \"go\")`\n\n\nI want to access that path in another recipe \"protoc-gen-go\"\
      \ as follows:\n```\ndef source(self):\n    self.go_run(\"mod init conan-center-protoc-gen-go\"\
      )\ndef go_run(self,cmd):\n    self.run(\"%s %s\" % (self.env['GO'], cmd), cwd=self.source_folder)\n\
      ```\n\nTo migrate this to conan2, in \"golang\" recipe, I changed the p...\n----------\n\
      Issue 2 (Number: 18049):\n  Title: [question] Is it possible to apply --build=missing\
      \ only to tool_requires?\n  Body (Preview):\n### What is your question?\n\nHi,\
      \ thank you for maintaining Conan!\nI have a question: is it possible to apply\
      \ `--build=missing` option only to `tool_requires`, and not to the regular `requires`?\n\
      \nFor example, I would like to ensure that all regular dependencies are already\
      \ available in the cache (or from a remote), but still allow missing `tool_requires`\
      \ to be built locally if necessary.\n\nThis becomes especially important when\
      \ migrating to environments into `Ubuntu 24.04` from `Ubuntu 22.04`, wher...\n\
      ----------\nIssue 3 (Number: 18053):\n  Title: [question] Migrate from Maven to\
      \ Conan\n  Body (Preview):\n### What is your question?\n\nHello, what would be\
      \ the workflow to migrate an existing Maven project to Conan ?\nActually, with\
      \ Maven, dependencies are called in pom.xml files and it can be zip, or tar.gz\
      \ file. They are retrieved from an Artifactory repo. How to migrate those dependencies\
      \ to conan packages ? Is it even possible to build conan packages from a zip archive\
      \ ?\nThank you :)\n\n### Have you read the CONTRIBUTING guide?\n\n- [x] I've read\
      \ the CONTRIBUTING guide\n----------\nIssue 4 (Number: 18074):\n  Title: [bug]\
      \ x86 build reports CMAKE_SYSTEM_PROCESSOR=AMD64 and not i386\n  Body: [Omitted\
      \ due to length (2074 > 2000 chars)]\n----------\nIssue 5 (Number: 18048):\n \
      \ Title: [migrate] Help me migrate our open source project Nativium\n  Body (Preview):\n\
      Hi,\n\nIm migrating the project Nativium (https://github.com/nativium/nativium)\
      \ from v1 to v2, believing that is support android/ios/watchos/tvos out-of-box\
      \ instead need use our darwin-toolchain package (https://github.com/nativium/nativium/tree/main/conan/darwin-toolchain)\
      \ anymore.\n\nI open a pull-request that show what i already changed in this migration.\n\
      \n- add `*:` to some options/settings\n- move `conanfile.py` to root\n- move some\
      \ paths to `conanfile.py` to root file (because previous step)\n\nPR...\n----------\n\
      (1 issue bodies omitted due to length limit of 2000 chars.)\n\n--- Pull Request\
      \ #18030 Details ---\nPR Title: add test_divergent_cppstd_build_host test\n\n\
      PR Body:\nChangelog: Omit\nDocs: Omit\n\n\n\n\n--- Issue Comments ---\n\nThe possible\
      \ fixes to change this behavior breaks https://github.com/conan-io/conan/pull/17643\
      \ added a couple of months ago for ``test_build_order_build_context_compatible()``\
      \ test.\n\nIf we change the behavior (it is easy), it might have implications\
      \ for ConanCenter having missing binaries in the build context?\n\nTo keep it\
      \ for future reference.\nIf we ever want to change the behavior to require different\
      \ build in \"build\" and \"host\", the change is:\n\n```diff\ndiff --git a/conans/client/graph/graph_binaries.py\
      \ b/conans/client/graph/graph_binaries.py \nindex cc4334bda..43eaf4164 100644\
      \                                                          \n--- a/conans/client/graph/graph_binaries.py\
      \                                                \n+++ b/conans/client/graph/graph_binaries.py\
      \                                                \n@@ -106,7 +106,7 @@ class GraphBinariesAnalyzer:\
      \                                           \n         exactly the same      \
      \                                                            \n         \"\"\"\
      \                                                                            \
      \   \n         pref = node.pref                                              \
      \                    \n-        previous_nodes = self._evaluated.get(pref)   \
      \                                     \n+        previous_nodes = self._evaluated.get((pref,\
      \ node.context))                        \n         if previous_nodes:        \
      \                                                        \n             previous_nodes.append(node)\
      \                                                   \n             previous_node\
      \ = previous_nodes[0]                                             \n@@ -121,7\
      \ +121,7 @@ class GraphBinariesAnalyzer:                                     \
      \      \n             # https://github.com/conan-io/conan/issues/9880        \
      \                       \n             node._package_id = previous_node.package_id\
      \                                   \n             return True               \
      \                                                    \n-        self._evaluated[pref]\
      \ = [node]                                                    \n+        self._evaluated[(pref,\
      \ node.context)] = [node]                                    \n```\n\n\n--- Commit\
      \ Messages ---\n\nadd test_divergent_cppstd_build_host test\n\nremove print\n\n\
      \n--- Diff ---\n\ndiff --git a/test/integration/graph/test_divergent_cppstd_build_host.py\
      \ b/test/integration/graph/test_divergent_cppstd_build_host.py\nnew file mode\
      \ 100644\nindex 00000000000..637786d50e8\n--- /dev/null\n+++ b/test/integration/graph/test_divergent_cppstd_build_host.py\n\
      @@ -0,0 +1,43 @@\n+import json\n+import textwrap\n+\n+from conan.test.assets.genconanfile\
      \ import GenConanfile\n+from conan.test.utils.tools import TestClient\n+\n+\n\
      +def test_divergent_cppstd_build_host():\n+\n+    c = TestClient()\n+    \n+ \
      \   conanfile = textwrap.dedent(\"\"\"\n+        [requires]\n+        waterfall/1.0\n\
      +        [tool_requires]\n+        rainbow/1.0\n+        \"\"\")\n+\n+    c.save({\"\
      waterfall/conanfile.py\": GenConanfile(\"waterfall\", \"1.0\").with_settings(\"\
      compiler\"),\n+            \"rainbow/conanfile.py\": GenConanfile(\"rainbow\"\
      , \"1.0\").with_settings(\"compiler\")\n+                                    \
      \            .with_requires(\"waterfall/1.0\"),\n+            \"conanfile.txt\"\
      : conanfile})\n+\n+\n+    c.run(\"export waterfall\")\n+    c.run(\"export rainbow\"\
      )\n+    c.run(f\"install . --build=missing -s compiler.cppstd=14 -s:b compiler.cppstd=17\
      \ --format=json\", redirect_stdout=\"graph.json\")\n+    graph = json.loads(c.load(\"\
      graph.json\"))\n+\n+\n+    # waterfall is twice in the graph: as a direct host\
      \ dependency, and an indirect build dependency\n+    assert graph['graph']['nodes']['1']['ref']\
      \ == \"waterfall/1.0#821e924dcef2f185dd651e6d434f9f95\"\n+    assert graph['graph']['nodes']['1']['context']\
      \ == \"host\"\n+\n+    assert graph['graph']['nodes']['3']['ref'] == \"waterfall/1.0#821e924dcef2f185dd651e6d434f9f95\"\
      \n+    assert graph['graph']['nodes']['3']['context'] == \"build\"\n+\n+    #\
      \ is this the right behaviour?\n+    # without the compatibility plugin, we would\
      \ require two different package_id in the same graph,\n+    # but because of compatibility\
      \ plugin, Conan graph uses a \"compatible\" package_id in the build context\n\
      +    # rather than the exact one\n+    assert graph['graph']['nodes']['1']['package_id']\
      \ == graph['graph']['nodes']['3']['package_id']\n+\n\n\n--- Task ---\nBased on\
      \ the PR details and the context from existing issues provided above, please generate\
      \ the text (title and body) for a new, plausible GitHub issue that the pull request\
      \ #18030 appears to resolve. Output only the issue title and body in markdown\
      \ format.\n"
    diff:
      "diff --git a/test/integration/graph/test_divergent_cppstd_build_host.py b/test/integration/graph/test_divergent_cppstd_build_host.py\n\
      new file mode 100644\nindex 00000000000..637786d50e8\n--- /dev/null\n+++ b/test/integration/graph/test_divergent_cppstd_build_host.py\n\
      @@ -0,0 +1,43 @@\n+import json\n+import textwrap\n+\n+from conan.test.assets.genconanfile\
      \ import GenConanfile\n+from conan.test.utils.tools import TestClient\n+\n+\n\
      +def test_divergent_cppstd_build_host():\n+\n+    c = TestClient()\n+    \n+ \
      \   conanfile = textwrap.dedent(\"\"\"\n+        [requires]\n+        waterfall/1.0\n\
      +        [tool_requires]\n+        rainbow/1.0\n+        \"\"\")\n+\n+    c.save({\"\
      waterfall/conanfile.py\": GenConanfile(\"waterfall\", \"1.0\").with_settings(\"\
      compiler\"),\n+            \"rainbow/conanfile.py\": GenConanfile(\"rainbow\"\
      , \"1.0\").with_settings(\"compiler\")\n+                                    \
      \            .with_requires(\"waterfall/1.0\"),\n+            \"conanfile.txt\"\
      : conanfile})\n+\n+\n+    c.run(\"export waterfall\")\n+    c.run(\"export rainbow\"\
      )\n+    c.run(f\"install . --build=missing -s compiler.cppstd=14 -s:b compiler.cppstd=17\
      \ --format=json\", redirect_stdout=\"graph.json\")\n+    graph = json.loads(c.load(\"\
      graph.json\"))\n+\n+\n+    # waterfall is twice in the graph: as a direct host\
      \ dependency, and an indirect build dependency\n+    assert graph['graph']['nodes']['1']['ref']\
      \ == \"waterfall/1.0#821e924dcef2f185dd651e6d434f9f95\"\n+    assert graph['graph']['nodes']['1']['context']\
      \ == \"host\"\n+\n+    assert graph['graph']['nodes']['3']['ref'] == \"waterfall/1.0#821e924dcef2f185dd651e6d434f9f95\"\
      \n+    assert graph['graph']['nodes']['3']['context'] == \"build\"\n+\n+    #\
      \ is this the right behaviour?\n+    # without the compatibility plugin, we would\
      \ require two different package_id in the same graph,\n+    # but because of compatibility\
      \ plugin, Conan graph uses a \"compatible\" package_id in the build context\n\
      +    # rather than the exact one\n+    assert graph['graph']['nodes']['1']['package_id']\
      \ == graph['graph']['nodes']['3']['package_id']\n+\n"
